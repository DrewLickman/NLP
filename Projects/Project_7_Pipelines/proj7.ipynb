{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drew Lickman\n",
    "\n",
    "CSCI 4820-001\n",
    "\n",
    "Project #7\n",
    "\n",
    "Due 12/??/24\n",
    "\n",
    "AI Disclaimer: A.I. Disclaimer: Work for this assignment was completed with the aid of artificial intelligence tools and comprehensive documentation of the names of, input provided to, and output obtained from, these tools is included as part of my assignment submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom NLP Project using 3 Hugging Face Pipelines\n",
    "### Dr. Sal Barbosa, Department of Computer Science, Middle Tennessee State University\n",
    "\n",
    "# Project Description\n",
    "This project is used to analyze the transcripts of the Federal Open Market Committees (FOMC).\n",
    "\n",
    "I chose this project because I believe it is important for people to get a quick and easy-to-understand analysis of the FOMC meetings. The FOMC \"reviews economic and financial conditions, determines the appropriate stance of monetary policy, and assesses the risks to its long-run goals of price stability and sustainable economic growth\". (https://www.federalreserve.gov/monetarypolicy/fomc.htm)\n",
    "\n",
    "The dataset I used is the FOMC transcripts from each of their meetings. I created a web scraper to read the FOMC website and download the PDFs.\n",
    "\n",
    "This JupyterNotebook will:\n",
    "\n",
    "1. Download PDF transcripts from the official FOMC website using `fomc-crawler.py`\n",
    "2. Convert the PDFs to text files with `pdf-to-txt.py`\n",
    "3. Use a slightly modified version of tabularisai's robust-sentiment-analysis (distil)BERT-based Sentiment Classification Model `https://huggingface.co/tabularisai/robust-sentiment-analysis`\n",
    "4. Summarize each document via pipeline of Falconsai's text_summarization Fine-Tuned T5 Small for Text Summarization Model `https://huggingface.co/Falconsai/text_summarization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used for fomc-crawler.py and pdf-to-txt.py\n",
    "# !pip install requests tqdm beautifulsoup4\n",
    "# !pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\drew1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\drew1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "nltk.download('punkt')\n",
    "import torch.optim as optim\n",
    "import plotly.graph_objects as go\n",
    "from   nltk.tokenize import sent_tokenize\n",
    "from   transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Load the Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite\n",
    "You must run `./data/fomc-crawler.py` and `./data/pdf-to-txt.py` to download all the FOMC transcripts first, then convert the PDFs to TXT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding press conference pages...\n",
      "\n",
      "Found 48 press conference pages.\n",
      "\n",
      "Gathering transcript PDF links...\n",
      "\n",
      "Found 46 transcript PDFs to download:\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20240131.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20240320.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20240501.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20240612.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/fomcpresconf20240731.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20240918.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20241107.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20230201.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20230322.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20230503.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20230614.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20230726.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20230920.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20231101.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20231213.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20220126.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20220316.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20220504.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20220615.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20220727.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20220921.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20221102.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20221214.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20210127.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20210317.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20210428.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20210616.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20210728.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20210922.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20211103.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20211215.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20200129.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20200429.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20200610.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20200729.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20200916.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20201105.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20201216.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20190130.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20190320.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20190501.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20190619.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20190731.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20190918.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20191030.pdf\n",
      "- https://www.federalreserve.gov/mediacenter/files/FOMCpresconf20191211.pdf\n",
      "\n",
      "Downloading PDFs...\n",
      "\n",
      "Skipping FOMCpresconf20240131.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20240320.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20240501.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20240612.pdf (already exists)\n",
      "\n",
      "Skipping fomcpresconf20240731.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20240918.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20241107.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20230201.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20230322.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20230503.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20230614.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20230726.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20230920.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20231101.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20231213.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20220126.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20220316.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20220504.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20220615.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20220727.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20220921.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20221102.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20221214.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20210127.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20210317.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20210428.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20210616.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20210728.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20210922.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20211103.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20211215.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20200129.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20200429.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20200610.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20200729.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20200916.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20201105.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20201216.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20190130.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20190320.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20190501.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20190619.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20190731.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20190918.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20191030.pdf (already exists)\n",
      "\n",
      "Skipping FOMCpresconf20191211.pdf (already exists)\n",
      "\n",
      "Download process completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/48 [00:00<?, ?it/s]\n",
      "  2%|▏         | 1/48 [00:00<00:16,  2.87it/s]\n",
      "  4%|▍         | 2/48 [00:00<00:15,  3.01it/s]\n",
      "  6%|▋         | 3/48 [00:01<00:15,  2.96it/s]\n",
      "  8%|▊         | 4/48 [00:01<00:14,  3.06it/s]\n",
      " 10%|█         | 5/48 [00:01<00:14,  2.97it/s]\n",
      " 12%|█▎        | 6/48 [00:02<00:14,  2.88it/s]\n",
      " 15%|█▍        | 7/48 [00:02<00:13,  2.98it/s]\n",
      " 17%|█▋        | 8/48 [00:02<00:13,  2.96it/s]\n",
      " 19%|█▉        | 9/48 [00:03<00:13,  2.87it/s]\n",
      " 21%|██        | 10/48 [00:03<00:12,  3.02it/s]\n",
      " 23%|██▎       | 11/48 [00:03<00:12,  2.96it/s]\n",
      " 25%|██▌       | 12/48 [00:04<00:12,  2.84it/s]\n",
      " 27%|██▋       | 13/48 [00:04<00:12,  2.73it/s]\n",
      " 29%|██▉       | 14/48 [00:04<00:12,  2.66it/s]\n",
      " 31%|███▏      | 15/48 [00:05<00:12,  2.71it/s]\n",
      " 33%|███▎      | 16/48 [00:05<00:11,  2.73it/s]\n",
      " 35%|███▌      | 17/48 [00:06<00:11,  2.66it/s]\n",
      " 38%|███▊      | 18/48 [00:06<00:10,  2.77it/s]\n",
      " 40%|███▉      | 19/48 [00:06<00:10,  2.85it/s]\n",
      " 42%|████▏     | 20/48 [00:07<00:09,  2.85it/s]\n",
      " 44%|████▍     | 21/48 [00:07<00:09,  2.86it/s]\n",
      " 46%|████▌     | 22/48 [00:07<00:09,  2.87it/s]\n",
      " 48%|████▊     | 23/48 [00:08<00:08,  2.91it/s]\n",
      " 50%|█████     | 24/48 [00:08<00:08,  2.99it/s]\n",
      " 52%|█████▏    | 25/48 [00:08<00:07,  2.95it/s]\n",
      " 54%|█████▍    | 26/48 [00:09<00:07,  2.90it/s]\n",
      " 56%|█████▋    | 27/48 [00:09<00:07,  2.90it/s]\n",
      " 58%|█████▊    | 28/48 [00:09<00:06,  2.96it/s]\n",
      " 60%|██████    | 29/48 [00:10<00:06,  2.89it/s]\n",
      " 62%|██████▎   | 30/48 [00:10<00:06,  2.88it/s]\n",
      " 65%|██████▍   | 31/48 [00:10<00:06,  2.79it/s]\n",
      " 67%|██████▋   | 32/48 [00:11<00:05,  2.85it/s]\n",
      " 69%|██████▉   | 33/48 [00:11<00:05,  2.96it/s]\n",
      " 71%|███████   | 34/48 [00:11<00:04,  2.95it/s]\n",
      " 73%|███████▎  | 35/48 [00:12<00:04,  2.86it/s]\n",
      " 75%|███████▌  | 36/48 [00:12<00:04,  2.81it/s]\n",
      " 77%|███████▋  | 37/48 [00:12<00:04,  2.72it/s]\n",
      " 79%|███████▉  | 38/48 [00:13<00:03,  2.68it/s]\n",
      " 81%|████████▏ | 39/48 [00:13<00:03,  2.65it/s]\n",
      " 83%|████████▎ | 40/48 [00:14<00:02,  2.88it/s]\n",
      " 85%|████████▌ | 41/48 [00:14<00:02,  2.82it/s]\n",
      " 88%|████████▊ | 42/48 [00:14<00:02,  2.87it/s]\n",
      " 90%|████████▉ | 43/48 [00:15<00:01,  3.00it/s]\n",
      " 92%|█████████▏| 44/48 [00:15<00:01,  2.63it/s]\n",
      " 94%|█████████▍| 45/48 [00:15<00:01,  2.60it/s]\n",
      " 96%|█████████▌| 46/48 [00:16<00:00,  2.66it/s]\n",
      " 98%|█████████▊| 47/48 [00:16<00:00,  2.80it/s]\n",
      "100%|██████████| 48/48 [00:16<00:00,  2.78it/s]\n",
      "100%|██████████| 48/48 [00:16<00:00,  2.84it/s]\n",
      "\n",
      "  0%|          | 0/46 [00:00<?, ?it/s]\n",
      "  2%|▏         | 1/46 [00:01<00:45,  1.00s/it]\n",
      "  4%|▍         | 2/46 [00:02<00:44,  1.00s/it]\n",
      "  7%|▋         | 3/46 [00:03<00:43,  1.00s/it]\n",
      "  9%|▊         | 4/46 [00:04<00:42,  1.00s/it]\n",
      " 11%|█         | 5/46 [00:05<00:41,  1.00s/it]\n",
      " 13%|█▎        | 6/46 [00:06<00:40,  1.00s/it]\n",
      " 15%|█▌        | 7/46 [00:07<00:39,  1.00s/it]\n",
      " 17%|█▋        | 8/46 [00:08<00:38,  1.00s/it]\n",
      " 20%|█▉        | 9/46 [00:09<00:37,  1.00s/it]\n",
      " 22%|██▏       | 10/46 [00:10<00:36,  1.00s/it]\n",
      " 24%|██▍       | 11/46 [00:11<00:35,  1.00s/it]\n",
      " 26%|██▌       | 12/46 [00:12<00:34,  1.00s/it]\n",
      " 28%|██▊       | 13/46 [00:13<00:33,  1.00s/it]\n",
      " 30%|███       | 14/46 [00:14<00:32,  1.00s/it]\n",
      " 33%|███▎      | 15/46 [00:15<00:31,  1.00s/it]\n",
      " 35%|███▍      | 16/46 [00:16<00:30,  1.00s/it]\n",
      " 37%|███▋      | 17/46 [00:17<00:29,  1.00s/it]\n",
      " 39%|███▉      | 18/46 [00:18<00:28,  1.00s/it]\n",
      " 41%|████▏     | 19/46 [00:19<00:27,  1.00s/it]\n",
      " 43%|████▎     | 20/46 [00:20<00:26,  1.00s/it]\n",
      " 46%|████▌     | 21/46 [00:21<00:25,  1.00s/it]\n",
      " 48%|████▊     | 22/46 [00:22<00:24,  1.00s/it]\n",
      " 50%|█████     | 23/46 [00:23<00:23,  1.00s/it]\n",
      " 52%|█████▏    | 24/46 [00:24<00:22,  1.00s/it]\n",
      " 54%|█████▍    | 25/46 [00:25<00:21,  1.00s/it]\n",
      " 57%|█████▋    | 26/46 [00:26<00:20,  1.00s/it]\n",
      " 59%|█████▊    | 27/46 [00:27<00:19,  1.00s/it]\n",
      " 61%|██████    | 28/46 [00:28<00:18,  1.00s/it]\n",
      " 63%|██████▎   | 29/46 [00:29<00:17,  1.00s/it]\n",
      " 65%|██████▌   | 30/46 [00:30<00:16,  1.00s/it]\n",
      " 67%|██████▋   | 31/46 [00:31<00:15,  1.00s/it]\n",
      " 70%|██████▉   | 32/46 [00:32<00:14,  1.00s/it]\n",
      " 72%|███████▏  | 33/46 [00:33<00:13,  1.00s/it]\n",
      " 74%|███████▍  | 34/46 [00:34<00:12,  1.00s/it]\n",
      " 76%|███████▌  | 35/46 [00:35<00:11,  1.00s/it]\n",
      " 78%|███████▊  | 36/46 [00:36<00:10,  1.00s/it]\n",
      " 80%|████████  | 37/46 [00:37<00:09,  1.00s/it]\n",
      " 83%|████████▎ | 38/46 [00:38<00:08,  1.00s/it]\n",
      " 85%|████████▍ | 39/46 [00:39<00:07,  1.00s/it]\n",
      " 87%|████████▋ | 40/46 [00:40<00:06,  1.00s/it]\n",
      " 89%|████████▉ | 41/46 [00:41<00:05,  1.00s/it]\n",
      " 91%|█████████▏| 42/46 [00:42<00:04,  1.00s/it]\n",
      " 93%|█████████▎| 43/46 [00:43<00:03,  1.00s/it]\n",
      " 96%|█████████▌| 44/46 [00:44<00:02,  1.00s/it]\n",
      " 98%|█████████▊| 45/46 [00:45<00:01,  1.00s/it]\n",
      "100%|██████████| 46/46 [00:46<00:00,  1.00s/it]\n",
      "100%|██████████| 46/46 [00:46<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# Scrape FOMC Transcripts from https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm\n",
    "# Please wait about 1 to 3 minutes.\n",
    "# Code written by Claude 3.5 Sonnet (New)\n",
    "!python ./data/fomc-crawler.py\n",
    "# Outputs to ./data/fomc_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch conversion completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 16:47:28,774 - INFO - Successfully generated FOMCpresconf20190130.txt\n",
      "2024-11-23 16:47:30,424 - INFO - Successfully generated FOMCpresconf20190320.txt\n",
      "2024-11-23 16:47:31,833 - INFO - Successfully generated FOMCpresconf20190501.txt\n",
      "2024-11-23 16:47:33,415 - INFO - Successfully generated FOMCpresconf20190619.txt\n",
      "2024-11-23 16:47:35,072 - INFO - Successfully generated FOMCpresconf20190731.txt\n",
      "2024-11-23 16:47:36,960 - INFO - Successfully generated FOMCpresconf20190918.txt\n",
      "2024-11-23 16:47:38,692 - INFO - Successfully generated FOMCpresconf20191030.txt\n",
      "2024-11-23 16:47:40,650 - INFO - Successfully generated FOMCpresconf20191211.txt\n",
      "2024-11-23 16:47:42,658 - INFO - Successfully generated FOMCpresconf20200129.txt\n",
      "2024-11-23 16:47:44,399 - INFO - Successfully generated FOMCpresconf20200429.txt\n",
      "2024-11-23 16:47:46,677 - INFO - Successfully generated FOMCpresconf20200610.txt\n",
      "2024-11-23 16:47:48,999 - INFO - Successfully generated FOMCpresconf20200729.txt\n",
      "2024-11-23 16:47:51,319 - INFO - Successfully generated FOMCpresconf20200916.txt\n",
      "2024-11-23 16:47:53,048 - INFO - Successfully generated FOMCpresconf20201105.txt\n",
      "2024-11-23 16:47:55,330 - INFO - Successfully generated FOMCpresconf20201216.txt\n",
      "2024-11-23 16:47:57,349 - INFO - Successfully generated FOMCpresconf20210127.txt\n",
      "2024-11-23 16:47:59,481 - INFO - Successfully generated FOMCpresconf20210317.txt\n",
      "2024-11-23 16:48:01,485 - INFO - Successfully generated FOMCpresconf20210428.txt\n",
      "2024-11-23 16:48:03,583 - INFO - Successfully generated FOMCpresconf20210616.txt\n",
      "2024-11-23 16:48:05,558 - INFO - Successfully generated FOMCpresconf20210728.txt\n",
      "2024-11-23 16:48:07,417 - INFO - Successfully generated FOMCpresconf20210922.txt\n",
      "2024-11-23 16:48:09,438 - INFO - Successfully generated FOMCpresconf20211103.txt\n",
      "2024-11-23 16:48:11,685 - INFO - Successfully generated FOMCpresconf20211215.txt\n",
      "2024-11-23 16:48:13,661 - INFO - Successfully generated FOMCpresconf20220126.txt\n",
      "2024-11-23 16:48:15,486 - INFO - Successfully generated FOMCpresconf20220316.txt\n",
      "2024-11-23 16:48:17,159 - INFO - Successfully generated FOMCpresconf20220504.txt\n",
      "2024-11-23 16:48:19,128 - INFO - Successfully generated FOMCpresconf20220615.txt\n",
      "2024-11-23 16:48:21,163 - INFO - Successfully generated FOMCpresconf20220727.txt\n",
      "2024-11-23 16:48:22,735 - INFO - Successfully generated FOMCpresconf20220921.txt\n",
      "2024-11-23 16:48:24,419 - INFO - Successfully generated FOMCpresconf20221102.txt\n",
      "2024-11-23 16:48:26,125 - INFO - Successfully generated FOMCpresconf20221214.txt\n",
      "2024-11-23 16:48:27,769 - INFO - Successfully generated FOMCpresconf20230201.txt\n",
      "2024-11-23 16:48:29,442 - INFO - Successfully generated FOMCpresconf20230322.txt\n",
      "2024-11-23 16:48:31,313 - INFO - Successfully generated FOMCpresconf20230503.txt\n",
      "2024-11-23 16:48:33,362 - INFO - Successfully generated FOMCpresconf20230614.txt\n",
      "2024-11-23 16:48:35,416 - INFO - Successfully generated FOMCpresconf20230726.txt\n",
      "2024-11-23 16:48:37,541 - INFO - Successfully generated FOMCpresconf20230920.txt\n",
      "2024-11-23 16:48:39,575 - INFO - Successfully generated FOMCpresconf20231101.txt\n",
      "2024-11-23 16:48:41,282 - INFO - Successfully generated FOMCpresconf20231213.txt\n",
      "2024-11-23 16:48:43,296 - INFO - Successfully generated FOMCpresconf20240131.txt\n",
      "2024-11-23 16:48:45,606 - INFO - Successfully generated FOMCpresconf20240320.txt\n",
      "2024-11-23 16:48:47,502 - INFO - Successfully generated FOMCpresconf20240501.txt\n",
      "2024-11-23 16:48:49,515 - INFO - Successfully generated FOMCpresconf20240612.txt\n",
      "2024-11-23 16:48:51,345 - INFO - Successfully generated fomcpresconf20240731.txt\n",
      "2024-11-23 16:48:53,214 - INFO - Successfully generated FOMCpresconf20240918.txt\n",
      "2024-11-23 16:48:54,889 - INFO - Successfully generated FOMCpresconf20241107.txt\n"
     ]
    }
   ],
   "source": [
    "#!pip install pdfplumber\n",
    "# Convert PDFs to TXT\n",
    "# Please wait 1 to 3 minutes\n",
    "# Code written by Claude 3.5 Sonnet (New)\n",
    "!python ./data/pdf-to-txt.py\n",
    "# Outputs to ./data/extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = \"./data/extracted_text\" # Local FOMC transcript data as .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 documents ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "# Save text files and their data to a dictionary\n",
    "txt_fileNames = [txt for txt in os.listdir(DATADIR) if txt.endswith('.txt')]\n",
    "# Print the title of each TXT file\n",
    "print(f\"{len(txt_fileNames)} documents ready for analysis!\")\n",
    "\n",
    "txt_data = [open(os.path.join(DATADIR, file), 'r', encoding='utf-8').read() for file in txt_fileNames]\n",
    "\n",
    "textDict = {fileName: data for fileName, data in zip(txt_fileNames, txt_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that splits an input text into chunks, and attempts to keep sentences together\n",
    "# Written by Claude 3.5 Sonnet (New)\n",
    "\n",
    "def chunk_text(text, max_chunk_size):\n",
    "    \"\"\"\n",
    "    Split text into chunks based on sentences to respect max token limit.\n",
    "    Tries to keep sentences together while staying under the token limit.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Rough approximation of tokens (words + punctuation)\n",
    "        sentence_length = len(sentence.split())\n",
    "        \n",
    "        if current_length + sentence_length > max_chunk_size:\n",
    "            if current_chunk:  # Save current chunk if it exists\n",
    "                chunks.append(' '.join(current_chunk))\n",
    "                current_chunk = [sentence]\n",
    "                current_length = sentence_length\n",
    "            else:  # Handle case where single sentence exceeds max_chunk_size\n",
    "                chunks.append(sentence)\n",
    "                current_chunk = []\n",
    "                current_length = 0\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "            current_length += sentence_length\n",
    "    \n",
    "    # Add the last chunk if it exists\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### (distil)BERT-based Sentiment Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you encounter an error, you may not have Windows Long Path support enabled. \n",
    "# You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: FOMCpresconf20190130.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 2.87%\n",
      "  Negative: 10.58%\n",
      "  Neutral: 63.98%\n",
      "  Positive: 15.65%\n",
      "  Very Positive: 6.92%\n",
      "\n",
      "File: FOMCpresconf20190320.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 3.92%\n",
      "  Negative: 8.50%\n",
      "  Neutral: 56.45%\n",
      "  Positive: 22.29%\n",
      "  Very Positive: 8.84%\n",
      "\n",
      "File: FOMCpresconf20190501.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 1.88%\n",
      "  Negative: 8.70%\n",
      "  Neutral: 65.71%\n",
      "  Positive: 17.21%\n",
      "  Very Positive: 6.50%\n",
      "\n",
      "File: FOMCpresconf20190619.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 1.36%\n",
      "  Negative: 5.72%\n",
      "  Neutral: 66.87%\n",
      "  Positive: 18.17%\n",
      "  Very Positive: 7.88%\n",
      "\n",
      "File: FOMCpresconf20190731.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 2.06%\n",
      "  Negative: 8.54%\n",
      "  Neutral: 64.95%\n",
      "  Positive: 16.42%\n",
      "  Very Positive: 8.03%\n",
      "\n",
      "File: FOMCpresconf20190918.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 2.01%\n",
      "  Negative: 10.05%\n",
      "  Neutral: 59.31%\n",
      "  Positive: 22.76%\n",
      "  Very Positive: 5.87%\n",
      "\n",
      "File: FOMCpresconf20191030.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 1.58%\n",
      "  Negative: 5.67%\n",
      "  Neutral: 56.67%\n",
      "  Positive: 23.32%\n",
      "  Very Positive: 12.76%\n",
      "\n",
      "File: FOMCpresconf20191211.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 1.77%\n",
      "  Negative: 9.13%\n",
      "  Neutral: 63.96%\n",
      "  Positive: 17.27%\n",
      "  Very Positive: 7.88%\n",
      "\n",
      "File: FOMCpresconf20200129.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 2.11%\n",
      "  Negative: 5.43%\n",
      "  Neutral: 67.35%\n",
      "  Positive: 17.15%\n",
      "  Very Positive: 7.96%\n",
      "\n",
      "File: FOMCpresconf20200429.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 12.30%\n",
      "  Negative: 11.99%\n",
      "  Neutral: 47.37%\n",
      "  Positive: 18.27%\n",
      "  Very Positive: 10.07%\n",
      "\n",
      "File: FOMCpresconf20200610.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 8.45%\n",
      "  Negative: 11.16%\n",
      "  Neutral: 43.96%\n",
      "  Positive: 18.20%\n",
      "  Very Positive: 18.23%\n",
      "\n",
      "File: FOMCpresconf20200729.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 7.01%\n",
      "  Negative: 14.82%\n",
      "  Neutral: 55.49%\n",
      "  Positive: 14.13%\n",
      "  Very Positive: 8.55%\n",
      "\n",
      "File: FOMCpresconf20200916.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 3.35%\n",
      "  Negative: 6.83%\n",
      "  Neutral: 59.22%\n",
      "  Positive: 18.53%\n",
      "  Very Positive: 12.07%\n",
      "\n",
      "File: FOMCpresconf20201105.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 1.97%\n",
      "  Negative: 4.81%\n",
      "  Neutral: 62.29%\n",
      "  Positive: 19.50%\n",
      "  Very Positive: 11.43%\n",
      "\n",
      "File: FOMCpresconf20201216.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 2.45%\n",
      "  Negative: 6.85%\n",
      "  Neutral: 54.78%\n",
      "  Positive: 19.21%\n",
      "  Very Positive: 16.71%\n",
      "\n",
      "File: FOMCpresconf20210127.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 4.71%\n",
      "  Negative: 10.74%\n",
      "  Neutral: 46.84%\n",
      "  Positive: 24.51%\n",
      "  Very Positive: 13.21%\n",
      "\n",
      "File: FOMCpresconf20210317.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 5.64%\n",
      "  Negative: 10.87%\n",
      "  Neutral: 63.54%\n",
      "  Positive: 13.64%\n",
      "  Very Positive: 6.31%\n",
      "\n",
      "File: FOMCpresconf20210428.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 4.30%\n",
      "  Negative: 12.64%\n",
      "  Neutral: 60.98%\n",
      "  Positive: 14.92%\n",
      "  Very Positive: 7.16%\n",
      "\n",
      "File: FOMCpresconf20210616.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 2.48%\n",
      "  Negative: 8.46%\n",
      "  Neutral: 65.81%\n",
      "  Positive: 13.78%\n",
      "  Very Positive: 9.47%\n",
      "\n",
      "File: FOMCpresconf20210728.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 3.44%\n",
      "  Negative: 9.73%\n",
      "  Neutral: 67.96%\n",
      "  Positive: 13.76%\n",
      "  Very Positive: 5.11%\n",
      "\n",
      "File: FOMCpresconf20210922.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 1.44%\n",
      "  Negative: 7.11%\n",
      "  Neutral: 63.97%\n",
      "  Positive: 16.17%\n",
      "  Very Positive: 11.31%\n",
      "\n",
      "File: FOMCpresconf20211103.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 1.85%\n",
      "  Negative: 5.92%\n",
      "  Neutral: 67.91%\n",
      "  Positive: 16.17%\n",
      "  Very Positive: 8.15%\n",
      "\n",
      "File: FOMCpresconf20211215.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 4.37%\n",
      "  Negative: 9.68%\n",
      "  Neutral: 58.18%\n",
      "  Positive: 15.42%\n",
      "  Very Positive: 12.35%\n",
      "\n",
      "File: FOMCpresconf20220126.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 4.06%\n",
      "  Negative: 9.45%\n",
      "  Neutral: 58.48%\n",
      "  Positive: 15.80%\n",
      "  Very Positive: 12.21%\n",
      "\n",
      "File: FOMCpresconf20220316.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 1.16%\n",
      "  Negative: 6.11%\n",
      "  Neutral: 62.50%\n",
      "  Positive: 18.67%\n",
      "  Very Positive: 11.55%\n",
      "\n",
      "File: FOMCpresconf20220504.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 2.98%\n",
      "  Negative: 7.73%\n",
      "  Neutral: 62.20%\n",
      "  Positive: 15.82%\n",
      "  Very Positive: 11.26%\n",
      "\n",
      "File: FOMCpresconf20220615.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 3.11%\n",
      "  Negative: 7.17%\n",
      "  Neutral: 55.43%\n",
      "  Positive: 21.36%\n",
      "  Very Positive: 12.94%\n",
      "\n",
      "File: FOMCpresconf20220727.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 4.36%\n",
      "  Negative: 14.77%\n",
      "  Neutral: 59.01%\n",
      "  Positive: 14.07%\n",
      "  Very Positive: 7.79%\n",
      "\n",
      "File: FOMCpresconf20220921.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 3.73%\n",
      "  Negative: 8.00%\n",
      "  Neutral: 56.99%\n",
      "  Positive: 20.75%\n",
      "  Very Positive: 10.53%\n",
      "\n",
      "File: FOMCpresconf20221102.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 3.11%\n",
      "  Negative: 8.03%\n",
      "  Neutral: 54.66%\n",
      "  Positive: 22.30%\n",
      "  Very Positive: 11.91%\n",
      "\n",
      "File: FOMCpresconf20221214.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 4.58%\n",
      "  Negative: 9.78%\n",
      "  Neutral: 52.16%\n",
      "  Positive: 20.75%\n",
      "  Very Positive: 12.73%\n",
      "\n",
      "File: FOMCpresconf20230201.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 3.01%\n",
      "  Negative: 5.38%\n",
      "  Neutral: 60.66%\n",
      "  Positive: 20.43%\n",
      "  Very Positive: 10.52%\n",
      "\n",
      "File: FOMCpresconf20230322.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 4.57%\n",
      "  Negative: 7.33%\n",
      "  Neutral: 58.42%\n",
      "  Positive: 21.36%\n",
      "  Very Positive: 8.32%\n",
      "\n",
      "File: FOMCpresconf20230503.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 1.14%\n",
      "  Negative: 4.35%\n",
      "  Neutral: 65.01%\n",
      "  Positive: 20.28%\n",
      "  Very Positive: 9.23%\n",
      "\n",
      "File: FOMCpresconf20230614.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 1.56%\n",
      "  Negative: 5.52%\n",
      "  Neutral: 64.05%\n",
      "  Positive: 19.41%\n",
      "  Very Positive: 9.46%\n",
      "\n",
      "File: FOMCpresconf20230726.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 3.66%\n",
      "  Negative: 7.09%\n",
      "  Neutral: 55.68%\n",
      "  Positive: 22.97%\n",
      "  Very Positive: 10.59%\n",
      "\n",
      "File: FOMCpresconf20230920.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 1.68%\n",
      "  Negative: 6.46%\n",
      "  Neutral: 63.06%\n",
      "  Positive: 19.50%\n",
      "  Very Positive: 9.31%\n",
      "\n",
      "File: FOMCpresconf20231101.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 2.13%\n",
      "  Negative: 7.71%\n",
      "  Neutral: 60.20%\n",
      "  Positive: 20.76%\n",
      "  Very Positive: 9.19%\n",
      "\n",
      "File: FOMCpresconf20231213.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 1.82%\n",
      "  Negative: 6.82%\n",
      "  Neutral: 65.97%\n",
      "  Positive: 16.23%\n",
      "  Very Positive: 9.16%\n",
      "\n",
      "File: FOMCpresconf20240131.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 0.65%\n",
      "  Negative: 3.14%\n",
      "  Neutral: 61.27%\n",
      "  Positive: 22.47%\n",
      "  Very Positive: 12.46%\n",
      "\n",
      "File: FOMCpresconf20240320.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 0.81%\n",
      "  Negative: 5.92%\n",
      "  Neutral: 70.81%\n",
      "  Positive: 16.30%\n",
      "  Very Positive: 6.16%\n",
      "\n",
      "File: FOMCpresconf20240501.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 3.30%\n",
      "  Negative: 8.90%\n",
      "  Neutral: 59.33%\n",
      "  Positive: 19.83%\n",
      "  Very Positive: 8.65%\n",
      "\n",
      "File: FOMCpresconf20240612.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 3.33%\n",
      "  Negative: 9.23%\n",
      "  Neutral: 55.40%\n",
      "  Positive: 22.44%\n",
      "  Very Positive: 9.60%\n",
      "\n",
      "File: fomcpresconf20240731.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 3.28%\n",
      "  Negative: 10.55%\n",
      "  Neutral: 68.93%\n",
      "  Positive: 11.31%\n",
      "  Very Positive: 5.93%\n",
      "\n",
      "File: FOMCpresconf20240918.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 2.09%\n",
      "  Negative: 6.12%\n",
      "  Neutral: 65.36%\n",
      "  Positive: 18.67%\n",
      "  Very Positive: 7.75%\n",
      "\n",
      "File: FOMCpresconf20241107.txt\n",
      "Predicted Sentiment: Neutral\n",
      "Probability Distribution:\n",
      "  Very Negative: 2.73%\n",
      "  Negative: 7.32%\n",
      "  Neutral: 71.08%\n",
      "  Positive: 13.76%\n",
      "  Very Positive: 5.11%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tabularisai's robust-sentiment-analysis used via pipeline:\n",
    "# Modified to be chunked for longer input texts\n",
    "# also outputs probability distribution, rather than just the highest result\n",
    "# Please wait 2 to 4 minutes.\n",
    "model_name = \"tabularisai/robust-sentiment-analysis\"\n",
    "sentimentAnalysis = pipeline(model=model_name, device=device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Pipeline from Hugging Face (copied from example on page, had to modify to get probability distribution)\n",
    "def predict_sentiment(text):\n",
    "\tinputs = tokenizer(text.lower(), return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\twith torch.no_grad():\n",
    "\t\toutputs = model(**inputs)\n",
    "\t\n",
    "\tprobabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\tpredicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "\t\n",
    "\tprobs_list = probabilities[0].tolist()\n",
    "\tsentiment_map = {0: \"Very Negative\", 1: \"Negative\", 2: \"Neutral\", 3: \"Positive\", 4: \"Very Positive\"}\n",
    "\t\n",
    "\t# Create a dictionary of sentiment labels and their probabilities\n",
    "\tsentiment_probs = {\n",
    "\t\t\t\t\t\tsentiment_map[i]: prob\n",
    "\t\t\t\t\t\tfor i, prob in enumerate(probs_list)\n",
    "\t\t\t\t\t\t}\n",
    "\n",
    "\treturn {\n",
    "\t\t\t'predicted_class': sentiment_map[predicted_class],\n",
    "\t\t\t'probabilities': sentiment_probs\n",
    "\t\t\t}\n",
    "\n",
    "def analyze_long_text(text, max_chunk_size):\n",
    "\t\"\"\"\n",
    "\tAnalyze sentiment of long text by breaking it into chunks and averaging results.\n",
    "\t\"\"\"\n",
    "\t# Clean text\n",
    "\ttext = text.replace('\\n', ' ').strip()\n",
    "\t\n",
    "\t# Split into chunks using existing chunk_text function\n",
    "\tchunks = chunk_text(text, max_chunk_size)\n",
    "\t\n",
    "\t# Analyze each chunk\n",
    "\tchunk_sentiments = {\"Very Negative\": 0, \"Negative\": 0, \"Neutral\": 0, \"Positive\": 0, \"Very Positive\": 0}\n",
    "\tvalid_chunks = 0\n",
    "\t\n",
    "\tfor chunk in chunks:\n",
    "\t\ttry:\n",
    "\t\t\tresult = predict_sentiment(chunk) # Uses modified pipeline\n",
    "\t\t\tfor sentiment, prob in result['probabilities'].items():\n",
    "\t\t\t\tchunk_sentiments[sentiment] += prob\n",
    "\t\t\tvalid_chunks += 1\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error processing chunk: {e}\")\n",
    "\t\t\tcontinue\n",
    "\t\n",
    "\t# Average the sentiments\n",
    "\tif valid_chunks > 0:\n",
    "\t\tfor sentiment in chunk_sentiments:\n",
    "\t\t\tchunk_sentiments[sentiment] /= valid_chunks\n",
    "\t\n",
    "\t# Determine overall sentiment\n",
    "\tmax_sentiment = max(chunk_sentiments.items(), key=lambda x: x[1])\n",
    "\t\n",
    "\treturn {\n",
    "\t\t\t'predicted_class': max_sentiment[0],\n",
    "\t\t\t'probabilities': chunk_sentiments\n",
    "\t\t\t}\n",
    "\n",
    "# Updated sentiment analysis loop\n",
    "sentimentCount = {\"Very Negative\": 0, \"Negative\": 0, \"Neutral\": 0, \"Positive\": 0, \"Very Positive\": 0}\n",
    "for txt in textDict:\n",
    "    try:\n",
    "        result = analyze_long_text(textDict[txt], max_chunk_size=256)\n",
    "        print(f\"File: {txt}\")\n",
    "        print(f\"Predicted Sentiment: {result['predicted_class']}\")\n",
    "        print(\"Probability Distribution:\")\n",
    "        for sentiment, prob in result['probabilities'].items():\n",
    "            print(f\"  {sentiment}: {prob * 100:.2f}%\")\n",
    "            sentimentCount[sentiment] += prob\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {txt}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Very Negative: \t3.18%\n",
      "Average Negative: \t8.19%\n",
      "Average Neutral: \t60.66%\n",
      "Average Positive: \t18.30%\n",
      "Average Very Positive: \t9.68%\n"
     ]
    }
   ],
   "source": [
    "# Print average sentiment confidence\n",
    "avgSentimentPcts = []\n",
    "for sentiment in sentimentCount:\n",
    "\tavgSentimentPcts.append(float(f\"{sentimentCount[sentiment]/len(textDict) * 100:.2f}\"))\n",
    "\tprint(f\"Average {sentiment}: \\t{sentimentCount[sentiment]/len(textDict) * 100:.2f}%\")\n",
    "#print(avgSentimentPcts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "#ff4d4d",
           "#ff8c8c",
           "#8c8c8c",
           "#7fbf7f",
           "#2eb82e"
          ]
         },
         "text": [
          "3.18%",
          "8.19%",
          "60.66%",
          "18.3%",
          "9.68%"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Very Negative",
          "Negative",
          "Neutral",
          "Positive",
          "Very Positive"
         ],
         "y": [
          3.18,
          8.19,
          60.66,
          18.3,
          9.68
         ]
        }
       ],
       "layout": {
        "bargap": 0.2,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Average FOMC Sentiment Distribution"
        },
        "xaxis": {
         "title": {
          "text": "Sentiment"
         }
        },
        "yaxis": {
         "range": [
          0,
          100
         ],
         "title": {
          "text": "Percentage (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data preparation\n",
    "sentiments = [\"Very Negative\", \"Negative\", \"Neutral\", \"Positive\", \"Very Positive\"]\n",
    "percentages = avgSentimentPcts\n",
    "colors = [\"#ff4d4d\", \"#ff8c8c\", \"#8c8c8c\", \"#7fbf7f\", \"#2eb82e\"]\n",
    "\n",
    "# Create the bar chart\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(\n",
    "        x=sentiments,\n",
    "        y=percentages,\n",
    "        marker_color=colors,\n",
    "        text=[f'{p}%' for p in percentages],\n",
    "        textposition='auto',\n",
    "    )\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Average FOMC Sentiment Distribution',\n",
    "    xaxis_title='Sentiment',\n",
    "    yaxis_title='Percentage (%)',\n",
    "    yaxis_range=[0, 100],\n",
    "    template='plotly_white',\n",
    "    bargap=0.2\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Summarize each document\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Falconsai's text_summarization used via pipeline:\n",
    "# Modified to be chunked for longer input texts\n",
    "# Please wait 14 - 18 minutes.\n",
    "summarizer = pipeline(model=\"Falconsai/text_summarization\", device=device)\n",
    "\n",
    "def summarize_long_text(text, summarizer, max_length_div, min_length_div, max_chunk_size):\n",
    "\t\"\"\"\n",
    "\tSummarize long text by breaking it into chunks and combining summaries.\n",
    "\t\"\"\"\n",
    "\t# Clean text\n",
    "\ttext = text.replace('\\n', ' ').strip()\n",
    "\t\n",
    "\t# Split into chunks\n",
    "\tchunks = chunk_text(text, max_chunk_size)\n",
    "\tchunkLen = len(chunks)\n",
    "\tmax_length = chunkLen // max_length_div\n",
    "\tmin_length = chunkLen // min_length_div\n",
    "\t# Summarize each chunk\n",
    "\tchunk_summaries = []\n",
    "\tfor chunk in chunks:\n",
    "\t\ttry:\n",
    "\t\t\tresult = summarizer(chunk, max_length=max_length, min_length=min_length) # Pipeline from Hugging Face\n",
    "\t\t\tchunk_summaries.append(result[0]['summary_text'])\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error processing chunk: {e}\")\n",
    "\t\t\tcontinue\n",
    "\t\n",
    "\t# Combine chunk summaries\n",
    "\tif len(chunks) == 1:\n",
    "\t\treturn chunk_summaries[0]\n",
    "\telse:\n",
    "\t\t# For multiple chunks, create a final summary of the combined summaries\n",
    "\t\tcombined_summary = ' '.join(chunk_summaries)\n",
    "\t\t\n",
    "\t\tword_count = len(combined_summary.split()) # Count words, not characters\n",
    "\t\ttry:\n",
    "\t\t\tmax_length = word_count // max_length_div\n",
    "\t\t\tmin_length = word_count // min_length_div\n",
    "\t\t\t\n",
    "\t\t\tfinal_summary = summarizer(combined_summary, \n",
    "\t\t\t\t\t\t\t\t\tmax_length=max_length,\n",
    "\t\t\t\t\t\t\t\t\tmin_length=min_length)[0]['summary_text']\n",
    "\t\t\treturn final_summary\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error in final summarization: {e}\")\n",
    "\t\t\treturn combined_summary\n",
    "\n",
    "for txt in textDict:\n",
    "\ttry:\n",
    "\t\tlength = len(textDict[txt])\n",
    "\t\tsummary = summarize_long_text(\n",
    "\t\t\ttext=textDict[txt],\n",
    "\t\t\tsummarizer=summarizer,\n",
    "\t\t\tmax_length_div=2, #divisor of chunk\n",
    "\t\t\tmin_length_div=10, #divisor of chunk\n",
    "\t\t\tmax_chunk_size=256  # Adjust based on model's token limit\n",
    "\t\t)\n",
    "\t\tsummary_dir = f\"./data/summaries\"\n",
    "\t\tif not os.path.exists(summary_dir):\n",
    "\t\t\tos.makedirs(summary_dir)\n",
    "\t\twith open(os.path.join(summary_dir, txt), \"w+\") as summary_file:\n",
    "\t\t\tsummary_file.write(f\"File: {txt}\\nSummary: {summary}\\n\")\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error processing {txt}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Embeddings Matrix\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Converting word tokens to index values\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Indexing of a short speech\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Padding Speeches\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Split Data into Training, Validation, and Test\n",
    "\n",
    "The data must be split into training and test data minimally. Many training loops can also use validation data at the end of each epoch, allowing a comparison between training and validation losses (if this value is high or growing it may indicate overfitting).\n",
    "\n",
    "The split for this demonstration will be 80% training and 10% each for test and validation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training/test split (validation will come from test portion)\n",
    "tt_split = int(len(features) * trainSplitPercent)\n",
    "\n",
    "train_x, valtest_x = features[:tt_split], features[tt_split:]\n",
    "train_y, valtest_y = encoded_labels[:tt_split], encoded_labels[tt_split:]\n",
    "\n",
    "# Validation/test split (further split test data into validation and test)\n",
    "vt_split = int(len(valtest_x) * validationSplitPercent) # Default 0.5\n",
    "val_x, test_x = valtest_x[:vt_split], valtest_x[vt_split:]\n",
    "val_y, test_y = valtest_y[:vt_split], valtest_y[vt_split:]\n",
    "\n",
    "# Show shapes of data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "\t\t\"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "\t\t\"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Batching and DataLoaders\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### The model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model Parameters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Neural Network Hyperparameters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Training Loop\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing the Model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Testing loop\n",
    "def rnn_test(test_loader):\n",
    "    # Turn off gradient calculations (saves time and compute resources)\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        # Variables for tracking losses\n",
    "        test_losses = [] \n",
    "        num_correct = 0\n",
    "    \n",
    "        true_list = []\n",
    "        pred_list = []\n",
    "    \n",
    "        # Place model in evaluation mode\n",
    "        rnn_model.eval()\n",
    "    \n",
    "        # Run test data through model\n",
    "        for inputs, labels in test_loader:\n",
    "    \n",
    "            # Move test data batch to GPU/CPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "            # Get predicted output\n",
    "            output = rnn_model(inputs)\n",
    "    \n",
    "            # Calculate the loss\n",
    "            # test_loss = rnn_criterion(output.squeeze(), labels.float())\n",
    "            test_loss = rnn_criterion(output.squeeze(), labels)\n",
    "            test_losses.append(test_loss.item())\n",
    "    \n",
    "            # Convert output sigmoid probabilities to predicted classes (0 or 1)\n",
    "            #pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "            pred = torch.argmax(output, dim=1)\n",
    "    \n",
    "            # Place true and predicted labels in list\n",
    "            true_list += list(labels.cpu().numpy())\n",
    "            pred_list += list(pred.cpu().numpy())\n",
    "    \n",
    "            # Compare predicted and true labels and count number of correct prediction\n",
    "            correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "            correct = np.squeeze(correct_tensor.numpy()) if device=='cpu' else np.squeeze(correct_tensor.cpu().numpy())\n",
    "            num_correct += np.sum(correct)\n",
    "    \n",
    "    pred_list = [a.squeeze().tolist() for a in pred_list]\n",
    "    print(confusion_matrix(true_list, pred_list))\n",
    "    print()\n",
    "    print(classification_report(true_list, pred_list))\n",
    "    print()\n",
    "    print(f\"Accuracy {accuracy_score(true_list, pred_list):.2%}\")\n",
    "    \n",
    "    # Output average test loss\n",
    "    print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "    \n",
    "    # Output average accuracy\n",
    "    test_acc = num_correct/len(test_loader.dataset)\n",
    "    print(\"Test accuracy: {:.3f}\".format(test_acc))\n",
    "\n",
    "rnn_test(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
