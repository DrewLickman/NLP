{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drew Lickman\\\n",
    "CSCI 4820-001\\\n",
    "Project #3\\\n",
    "Due: 10/9/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.I. Disclaimer: Work for this assignment was completed with the aid of artificial intelligence tools and comprehensive documentation of the names of, input provided to, and output obtained from, these tools is included as part of my assignment submission in ai_usage.pdf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon-Based Sentiment Analysis using Custom Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Requirements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "---\n",
    "\n",
    "- Positive words\n",
    "- Negative words\n",
    "- IMDb reviews\n",
    "\n",
    "### Processing\n",
    "---\n",
    "\n",
    "- There are two classifiers\n",
    "\t- Custom Logistic Regression\n",
    "\t- sklearn LogisticRegression\n",
    "- Implement a Python class (CustomLogisticRegression)\n",
    "\t- \\__init\\__(self, learning_rate, num_iters)\n",
    "\t\t- self.learning_rate\n",
    "\t\t- self.num_iters\n",
    "\t\t- self.weights\n",
    "\t\t- self.bias\n",
    "\t- sigmoid(z)\n",
    "\t\t- return sigmoid function\n",
    "\t- fit(X, y)\n",
    "\t\t- Sets weights to correct shape and initializes them to 0\n",
    "\t\t- Applies batch gradient descent to the entire dataset in a loop for num_iters\n",
    "\t\t- Updated weights and biases\n",
    "\t- predict(X)\n",
    "\t\t- z = w dot x + b\n",
    "\t\t- return sigmoid(z) \n",
    "\n",
    "### Output\n",
    "---\n",
    "\n",
    "- For each trial and for each classifier\n",
    "\t- Print the sklearn confusion_matrix and classification_Report\n",
    "- Output the average of the confusion matrices across trials for each classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load and process positive and negative sentiment lexicon words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentWords = []\n",
    "posWords = []\n",
    "negWords = []\n",
    "# Save positive words to array\n",
    "with open(\"positive-words.txt\", encoding=\"utf-8\") as positivewords:\n",
    "\tlines = positivewords.readlines()\n",
    "\tfor line in lines:\n",
    "\t\tif line[0] != \";\" and line.strip() != '': \n",
    "\t\t\tposWords.append(line.rstrip('\\n'))\n",
    "# Save negative words to array\n",
    "with open(\"negative-words.txt\", encoding=\"utf-8\") as negativewords:\n",
    "\tlines = negativewords.readlines()\n",
    "\tfor line in lines:\n",
    "\t\tif line[0] != \";\" and line.strip() != '':\n",
    "\t\t\tnegWords.append(line.rstrip('\\n'))\n",
    "sentimentWords = posWords + negWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load and process IMDb reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add each line of the IMDb reviews to the reviews array\n",
    "reviews = []\n",
    "trueValues = []\n",
    "with open(\"imdb_reviews.txt\", encoding=\"utf-8\") as imdbreviews:\n",
    "\tlines = imdbreviews.readlines()\n",
    "\tfor line in lines:\n",
    "\t\tsplitLine = line.rstrip().rsplit(' ', 1)\n",
    "\t\treviews.append(splitLine[0]) # removes true sentiment label from data\n",
    "\n",
    "\t\tsentiment = splitLine[1].strip()[-8:] # the last 8 characters are either positive or negative\n",
    "\t\tif sentiment == \"positive\":\n",
    "\t\t\ttrueValues.append(1)\n",
    "\t\telif sentiment == \"negative\":\n",
    "\t\t\ttrueValues.append(0)\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Error: sentiment analysis not found at end of line!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create Features(X) table and Labels(y) array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.zeros((len(reviews), len(sentimentWords)), dtype=bool) \t# Features\t\t\t\t\t\t\t\n",
    "y = np.array(trueValues, dtype=int)\t\t\t\t\t\t\t\t# Labels\n",
    "\n",
    "# Count how many positive / negative words show up in each review\n",
    "posCount = 0\n",
    "negCount = 0\n",
    "\n",
    "# If a sentiment word is in the review, mark it as True in the X feature table\n",
    "for review in range(len(reviews)): \t\t\t\t\t# 25,000 \n",
    "\tfor word in range(len(sentimentWords)):\t\t\t# * 6,786 \n",
    "\t\tif sentimentWords[word] in reviews[review]: # = 169,650,000 loops\n",
    "\t\t\tX[review, word] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Debug viewing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\tprint(X.shape)\n",
    "\tprint(y.shape)\n",
    "\t# Only show the first 10 reviews to make sure things are loading properly\n",
    "\tfor review in range(10):\n",
    "\t\t#print(reviews[review])\n",
    "\t\tfor sentimentWord in range(len(sentimentWords)):\n",
    "\t\t\tif X[review, sentimentWord] == True:\n",
    "\t\t\t\t# Prints all sentiment words that occur in each review line\n",
    "\t\t\t\tprint(f\"{sentimentWords[sentimentWord]}\", end=\" \") \n",
    "\t\t\t\t#print(X[review, sentimentWord])\n",
    "\t\t\t\t# \t\n",
    "\t\t# Display if a review is positive or negative\n",
    "\t\tprint()\n",
    "\t\tif y[review] == 1:\n",
    "\t\t\tprint(f\"Review {review} is positive!\")\n",
    "\t\telif y[review] == 0:\n",
    "\t\t\tprint(f\"Review {review} is negative!\")\n",
    "\t\tprint(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define Custom Logistic Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression():\n",
    "\t# Constructor\n",
    "\tdef __init__(self, learning_rate, num_iters): \n",
    "\t\tself.learning_rate = learning_rate\n",
    "\t\tself.num_iters = num_iters\n",
    "\t\tself.weights = None\n",
    "\t\tself.bias = None\n",
    "\n",
    "\t# Function for X dot W + b\n",
    "\tdef linearTransform(self, X):\n",
    "\t\tz = np.dot(X, self.weights) + self.bias\n",
    "\t\treturn z\n",
    "\t\n",
    "\t# Inputs either scalar or array and outputs sigmoid function of the scalar or array\n",
    "\tdef sigmoid(self, z):\n",
    "\t\t# Formula from LogisticRegression slide 28\n",
    "\t\toutput = 1 / (1 + np.exp(-z)) # np.exp does e^(-z) for all samples in the reviews array\n",
    "\t\treturn output\n",
    "\n",
    "\t# Calculate probability of a sample being a class (positive or negative)\n",
    "\tdef predict(self, X):\n",
    "\t\tprob = self.sigmoid(self.linearTransform(X))\n",
    "\t\t#prob = int(prob >= 0.5) # Convert to binary output\n",
    "\t\treturn prob\n",
    "\t\n",
    "\t# Train the model using gradient descent\n",
    "\t# X is training features, y is labels\n",
    "\tdef fit(self, X, y):\n",
    "\t\t# Sets the weights to the correct shape and initializes them to 0\n",
    "\t\tfeatures = X.shape[1] # Literally just how many sentiment words there are\n",
    "\t\tself.weights = np.zeros(features) # weight for each feature\n",
    "\t\tself.bias = 0\n",
    "\n",
    "\t\t# Apply batch gradient descent on entire dataset\n",
    "\t\t# This for loop was written by Claude 3.5 Sonnet and modified by myself\n",
    "\t\tfor _ in range(self.num_iters): \t# Apply gradient descent num_iters times\n",
    "\t\t\tpredictions = self.predict(X) \t# Calculate array of sigmoidal probabilities\n",
    "\t\t\terror = predictions - y \t\t# Calculate the difference between predicted and actual labels\n",
    "\n",
    "\t\t\t# Compute gradient for weights\n",
    "\t\t\t# Calculate how much each feature contributes to the error across all samples\n",
    "\t\t\tweightGradient = (1 / len(y)) * np.dot(X.T, error)\t# X.T is transposed \n",
    "\t\t\t# Compute gradient for bias\n",
    "\t\t\t# Calculate how much bias needs to be adjusted based on overall error\n",
    "\t\t\tbiasGradient = (1 / len(y)) * np.sum(error) \t\t# Average of all errors\n",
    "\n",
    "\t\t\t# Update weights and biases\n",
    "\t\t\tself.weights -= self.learning_rate * weightGradient\n",
    "\t\t\tself.bias -= self.learning_rate * biasGradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run 5 trials of the SKLearn Linear Model\n",
    "\n",
    "scikit-learn documentation\n",
    "\t\n",
    "\t- https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict\n",
    "\n",
    "\t- https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\t\n",
    "\t- https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 - Sklearn LogisticRegression:\n",
      "[[1993  525]\n",
      " [ 390 2092]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.84      0.79      0.81      2518\n",
      "    Negative       0.80      0.84      0.82      2482\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.82      0.82      0.82      5000\n",
      "weighted avg       0.82      0.82      0.82      5000\n",
      "\n",
      "Trial 1 - Custom LogisticRegression:\n",
      "[[1975  543]\n",
      " [ 428 2054]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.82      0.78      0.80      2518\n",
      "    Negative       0.79      0.83      0.81      2482\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.81      0.81      0.81      5000\n",
      "weighted avg       0.81      0.81      0.81      5000\n",
      "\n",
      "Trial 2 - Sklearn LogisticRegression:\n",
      "[[2012  530]\n",
      " [ 395 2063]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.84      0.79      0.81      2542\n",
      "    Negative       0.80      0.84      0.82      2458\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.82      0.82      0.81      5000\n",
      "weighted avg       0.82      0.81      0.81      5000\n",
      "\n",
      "Trial 2 - Custom LogisticRegression:\n",
      "[[1972  570]\n",
      " [ 430 2028]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.82      0.78      0.80      2542\n",
      "    Negative       0.78      0.83      0.80      2458\n",
      "\n",
      "    accuracy                           0.80      5000\n",
      "   macro avg       0.80      0.80      0.80      5000\n",
      "weighted avg       0.80      0.80      0.80      5000\n",
      "\n",
      "Trial 3 - Sklearn LogisticRegression:\n",
      "[[2006  510]\n",
      " [ 404 2080]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.83      0.80      0.81      2516\n",
      "    Negative       0.80      0.84      0.82      2484\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.82      0.82      0.82      5000\n",
      "weighted avg       0.82      0.82      0.82      5000\n",
      "\n",
      "Trial 3 - Custom LogisticRegression:\n",
      "[[1962  554]\n",
      " [ 435 2049]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.82      0.78      0.80      2516\n",
      "    Negative       0.79      0.82      0.81      2484\n",
      "\n",
      "    accuracy                           0.80      5000\n",
      "   macro avg       0.80      0.80      0.80      5000\n",
      "weighted avg       0.80      0.80      0.80      5000\n",
      "\n",
      "Trial 4 - Sklearn LogisticRegression:\n",
      "[[1995  462]\n",
      " [ 427 2116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.82      0.81      0.82      2457\n",
      "    Negative       0.82      0.83      0.83      2543\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.82      0.82      0.82      5000\n",
      "weighted avg       0.82      0.82      0.82      5000\n",
      "\n",
      "Trial 4 - Custom LogisticRegression:\n",
      "[[1967  490]\n",
      " [ 461 2082]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.81      0.80      0.81      2457\n",
      "    Negative       0.81      0.82      0.81      2543\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.81      0.81      0.81      5000\n",
      "weighted avg       0.81      0.81      0.81      5000\n",
      "\n",
      "Trial 5 - Sklearn LogisticRegression:\n",
      "[[2015  497]\n",
      " [ 407 2081]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.83      0.80      0.82      2512\n",
      "    Negative       0.81      0.84      0.82      2488\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.82      0.82      0.82      5000\n",
      "weighted avg       0.82      0.82      0.82      5000\n",
      "\n",
      "Trial 5 - Custom LogisticRegression:\n",
      "[[1980  532]\n",
      " [ 453 2035]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.81      0.79      0.80      2512\n",
      "    Negative       0.79      0.82      0.81      2488\n",
      "\n",
      "    accuracy                           0.80      5000\n",
      "   macro avg       0.80      0.80      0.80      5000\n",
      "weighted avg       0.80      0.80      0.80      5000\n",
      "\n",
      "Average Confusion Matrix - Sklearn LogisticRegression:\n",
      "[[2004.2  504.8]\n",
      " [ 404.6 2086.4]]\n",
      "Average Confusion Matrix - Custom LogisticRegression:\n",
      "[[1971.2  537.8]\n",
      " [ 441.4 2049.6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model as lm\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import metrics\n",
    "\n",
    "# Initialize variables to store average confusion matrices\n",
    "avgConfusionMatrix_skllr = np.zeros((2, 2))\n",
    "avgConfusionMatrix_mylr = np.zeros((2, 2))\n",
    "\n",
    "trialCount = 5\n",
    "iterationCount = 50\n",
    "for trial in range(trialCount):\n",
    "\t# Shuffle input data\n",
    "\t# Split into 80% 20% split of training and test sets\n",
    "\t# Line from Claude 3.5 Sonnet\n",
    "\tX_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state=trial)\n",
    "\tskllr = lm.LogisticRegression(solver='sag', C=0.001, max_iter=iterationCount)\n",
    "\tskllr.fit(X_train, y_train) # Only use the 80% of the data marked for training #takes a long time\t\n",
    "\tskllrPredictions = skllr.predict(X_test) # Use the remaining 20% of the data marked for testing\n",
    "\t\t\n",
    "\t# Initialize CustomLogisticRegression class,\n",
    "\t# Then train it over iterationCount times, which adjusts the weights and bias\n",
    "\t# Then predict each sample, using the updated weights and bias\n",
    "\tmylr = CustomLogisticRegression(learning_rate=0.1, num_iters=iterationCount)\t\n",
    "\tmylr.fit(X_train, y_train) # Only use the 80% of the data marked for training #takes a long time\n",
    "\t#mylrPredictions = np.array([1 if mylr.predict(x) >= 0.5 else 0 for x in X_test]) # Use the remaining 20% of the data marked for testing\t\n",
    "\tmylrPredictions = (mylr.predict(X_test) >= 0.5).astype(int)\n",
    "\t# for i in skllrPredictions:\n",
    "\t# \tprint(skllrPredictions[i], end=\" \")\n",
    "\t# \tprint(mylrPredictions[i])\n",
    "\t\n",
    "\t# Evaluate sklearn model\n",
    "\tprint(f\"Trial {trial + 1} - Sklearn LogisticRegression:\")\n",
    "\tprint(metrics.confusion_matrix(y_test, skllrPredictions))\n",
    "\tprint(metrics.classification_report(y_test, skllrPredictions, target_names=[\"Positive\", \"Negative\"]))\n",
    "\t# Evaluate custom model\n",
    "\tprint(f\"Trial {trial + 1} - Custom LogisticRegression:\")\n",
    "\tprint(metrics.confusion_matrix(y_test, mylrPredictions))\n",
    "\tprint(metrics.classification_report(y_test, mylrPredictions, target_names=[\"Positive\", \"Negative\"]))\n",
    "\t# Update average confusion matrices\n",
    "\tavgConfusionMatrix_skllr += metrics.confusion_matrix(y_test, skllrPredictions)\n",
    "\tavgConfusionMatrix_mylr += metrics.confusion_matrix(y_test, mylrPredictions)\n",
    "# Calculate and print average confusion matrices\n",
    "avgConfusionMatrix_skllr /= 5\n",
    "avgConfusionMatrix_mylr /= 5\n",
    "\n",
    "# After all trials are completed, print average of the trials\n",
    "print(\"Average Confusion Matrix - Sklearn LogisticRegression:\")\n",
    "print(avgConfusionMatrix_skllr)\n",
    "\n",
    "print(\"Average Confusion Matrix - Custom LogisticRegression:\")\n",
    "print(avgConfusionMatrix_mylr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
