{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drew Lickman\\\n",
    "CSCI 4820-001\\\n",
    "Project #3\\\n",
    "Due: 10/9/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.I. Disclaimer: Work for this assignment was completed with the aid of artificial intelligence tools and comprehensive documentation of the names of, input provided to, and output obtained from, these tools is included as part of my assignment submission in ai_usage.pdf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon-Based Sentiment Analysis using Custom Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Requirements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "---\n",
    "\n",
    "- Positive words\n",
    "- Negative words\n",
    "- IMDb reviews\n",
    "\n",
    "### Processing\n",
    "---\n",
    "\n",
    "- There are two classifiers\n",
    "\t- Custom Logistic Regression\n",
    "\t- sklearn LogisticRegression\n",
    "- Implement a Python class (CustomLogisticRegression)\n",
    "\t- \\__init\\__(self, learning_rate, num_iters)\n",
    "\t\t- self.learning_rate\n",
    "\t\t- self.num_iters\n",
    "\t\t- self.weights\n",
    "\t\t- self.bias\n",
    "\t- sigmoid(z)\n",
    "\t\t- return sigmoid function\n",
    "\t- fit(X, y)\n",
    "\t\t- Sets weights to correct shape and initializes them to 0\n",
    "\t\t- Applies batch gradient descent to the entire dataset in a loop for num_iters\n",
    "\t\t- Updated weights and biases\n",
    "\t- predict(X)\n",
    "\t\t- z = w dot x + b\n",
    "\t\t- return sigmoid(z) \n",
    "\n",
    "### Output\n",
    "---\n",
    "\n",
    "- For each trial and for each classifier\n",
    "\t- Print the sklearn confusion_matrix and classification_Report\n",
    "- Output the average of the confusion matrices across trials for each classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load and process positive and negative sentiment lexicon words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentWords = []\n",
    "posWords = []\n",
    "negWords = []\n",
    "# Save positive words to array\n",
    "with open(\"positive-words.txt\", encoding=\"utf-8\") as positivewords:\n",
    "\tlines = positivewords.readlines()\n",
    "\tfor line in lines:\n",
    "\t\tif line[0] != \";\" and line.strip() != '': \n",
    "\t\t\tposWords.append(line.rstrip('\\n'))\n",
    "# Save negative words to array\n",
    "with open(\"negative-words.txt\", encoding=\"utf-8\") as negativewords:\n",
    "\tlines = negativewords.readlines()\n",
    "\tfor line in lines:\n",
    "\t\tif line[0] != \";\" and line.strip() != '':\n",
    "\t\t\tnegWords.append(line.rstrip('\\n'))\n",
    "sentimentWords = posWords + negWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load and process IMDb reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add each line of the IMDb reviews to the reviews array\n",
    "reviews = []\n",
    "trueValues = []\n",
    "with open(\"imdb_reviews.txt\", encoding=\"utf-8\") as imdbreviews:\n",
    "\tlines = imdbreviews.readlines()\n",
    "\tfor line in lines:\n",
    "\t\tsplitLine = line.rstrip().rsplit(' ', 1)\n",
    "\t\treviews.append(splitLine[0]) # removes true sentiment label from data\n",
    "\n",
    "\t\tsentiment = splitLine[1].strip()[-8:] # the last 8 characters are either positive or negative\n",
    "\t\tif sentiment == \"positive\":\n",
    "\t\t\ttrueValues.append(1)\n",
    "\t\telif sentiment == \"negative\":\n",
    "\t\t\ttrueValues.append(0)\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Error: sentiment analysis not found at end of line!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create Features(X) table and Labels(y) array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.zeros((len(reviews), len(sentimentWords)), dtype=bool) \t# Features\t\t\t\t\t\t\t\n",
    "y = np.array(trueValues, dtype=int)\t\t\t\t\t\t\t\t# Labels\n",
    "\n",
    "# Count how many positive / negative words show up in each review\n",
    "posCount = 0\n",
    "negCount = 0\n",
    "\n",
    "# If a sentiment word is in the review, mark it as True in the X feature table\n",
    "# for review in range(len(reviews)): \t\t\t\t\t# 25,000 \n",
    "# \tfor word in range(len(sentimentWords)):\t\t\t\t# * 6,786 \n",
    "# \t\tif sentimentWords[word] in reviews[review]: \t# = 169,650,000 loops\n",
    "# \t\t\tX[review, word] = True\t\t\t\t\t\t# Takes 2-5 minutes\n",
    "\n",
    "# cursor-small improved my time complexity from O(n*m*k) to O(n*k)\n",
    "# Convert sentimentWords list to a set for faster membership testing\n",
    "sentimentWords_set = set(sentimentWords) # Convert array to unsorted set \n",
    "for review_index, review in enumerate(reviews):\n",
    "    words = review.split() # Check each word in every review line\n",
    "    for word in words:\n",
    "        if word in sentimentWords_set:  # This check is now O(1) by using set data structure\n",
    "            X[review_index, sentimentWords.index(word)] = True\t# Reduces time to <15 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Debug viewing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\tprint(X.shape)\n",
    "\tprint(y.shape)\n",
    "\t# Only show the first 10 reviews to make sure things are loading properly\n",
    "\tfor review in range(10):\n",
    "\t\tprint(reviews[review])\n",
    "\t\tfor sentimentWord in range(len(sentimentWords)):\n",
    "\t\t\tif X[review, sentimentWord] == True:\n",
    "\t\t\t\t# Prints all sentiment words that occur in each review line\n",
    "\t\t\t\tprint(f\"{sentimentWords[sentimentWord]}\", end=\" \") \t\n",
    "\t\t# Display if a review is positive or negative\n",
    "\t\tprint()\n",
    "\t\tif y[review] == 1:\n",
    "\t\t\tprint(f\"Review {review} is positive!\")\n",
    "\t\telif y[review] == 0:\n",
    "\t\t\tprint(f\"Review {review} is negative!\")\n",
    "\t\tprint(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define Custom Logistic Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression():\n",
    "\t# Constructor\n",
    "\tdef __init__(self, learning_rate, num_iters): \n",
    "\t\tself.learning_rate = learning_rate\n",
    "\t\tself.num_iters = num_iters\n",
    "\t\tself.weights = None\n",
    "\t\tself.bias = None\n",
    "\n",
    "\t# Function for X dot W + b\n",
    "\tdef linearTransform(self, X):\n",
    "\t\tz = np.dot(X, self.weights) + self.bias\n",
    "\t\treturn z\n",
    "\t\n",
    "\t# Inputs either scalar or array and outputs sigmoid function of the scalar or array\n",
    "\tdef sigmoid(self, z):\n",
    "\t\t# Formula from LogisticRegression slide 28\n",
    "\t\toutput = 1 / (1 + np.exp(-z)) # np.exp does e^(-z) for all samples in the reviews array\n",
    "\t\treturn output\n",
    "\n",
    "\t# Calculate probability of a sample being a class (positive or negative)\n",
    "\tdef predict(self, X):\n",
    "\t\tprob = self.sigmoid(self.linearTransform(X))\n",
    "\t\t#prob = int(prob >= 0.5) # Convert to binary output\n",
    "\t\treturn prob\n",
    "\t\n",
    "\t# Train the model using gradient descent\n",
    "\t# X is training features, y is labels\n",
    "\tdef fit(self, X, y):\n",
    "\t\t# Sets the weights to the correct shape and initializes them to 0\n",
    "\t\tfeatures = X.shape[1] # Literally just how many sentiment words there are\n",
    "\t\tself.weights = np.zeros(features) # weight for each feature\n",
    "\t\tself.bias = 0\n",
    "\n",
    "\t\t# Apply batch gradient descent on entire dataset\n",
    "\t\t# This for loop was written by Claude 3.5 Sonnet and modified by myself\n",
    "\t\tfor _ in range(self.num_iters): \t# Apply gradient descent num_iters times\n",
    "\t\t\tpredictions = self.predict(X) \t# Calculate array of sigmoidal probabilities\n",
    "\t\t\terror = predictions - y \t\t# Calculate the difference between predicted and actual labels\n",
    "\n",
    "\t\t\t# Compute gradient for weights\n",
    "\t\t\t# Calculate how much each feature contributes to the error across all samples\n",
    "\t\t\tweightGradient = (1 / len(y)) * np.dot(X.T, error)\t# X.T is transposed\n",
    "\t\t\t# Compute gradient for bias\n",
    "\t\t\t# Calculate how much bias needs to be adjusted based on overall error\n",
    "\t\t\tbiasGradient = (1 / len(y)) * np.sum(error) \t\t# Average of all errors\n",
    "\n",
    "\t\t\t# Update weights and biases\n",
    "\t\t\tself.weights -= self.learning_rate * weightGradient\n",
    "\t\t\tself.bias -= self.learning_rate * biasGradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run 5 trials of the SKLearn Linear Model\n",
    "\n",
    "scikit-learn documentation\n",
    "\n",
    "\t- https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.train_test_split.html \n",
    "\n",
    "\t- https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit \n",
    "\t\n",
    "\t- https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict\n",
    "\n",
    "\t- https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\t\n",
    "\t- https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import metrics\n",
    "\n",
    "# Initialize variables to store average confusion matrices\n",
    "avgConfusionMatrix_skllr = np.zeros((2, 2))\n",
    "avgConfusionMatrix_mylr = np.zeros((2, 2))\n",
    "\n",
    "trialCount = 5\n",
    "iterationCount = 500\n",
    "# Takes about 20 seconds per combined 1*10 iterations; \n",
    "# Combined: 1*500 took 8 minutes, 5*500 took 40 minutes\n",
    "# SKLearn LR: takes about 15 seconds for 500 iterations\n",
    "# My Custom LR: takes almost 8 minutes for 500 iterations\n",
    "for trial in range(trialCount):\n",
    "\t# Shuffle input data\n",
    "\t# Split into 80% 20% split of training and test sets\n",
    "\t# Line from Claude 3.5 Sonnet\n",
    "\tX_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state=trial)\n",
    "\n",
    "\t# SKLearn library Logistic Regression class and methods\n",
    "\tskllr = lm.LogisticRegression(solver='sag', C=0.001, max_iter=iterationCount)\n",
    "\tskllr.fit(X_train, y_train) \t\t\t\t# Only use the 80% of the data marked for training, takes a long time\t\n",
    "\tskllrPredictions = skllr.predict(X_test) \t# Use the remaining 20% of the data marked for testing\n",
    "\t\t\n",
    "\t# Initialize CustomLogisticRegression class,\n",
    "\t# Then train it over iterationCount times, which adjusts the weights and bias\n",
    "\t# Then predict each sample, using the updated weights and bias\n",
    "\tmylr = CustomLogisticRegression(learning_rate=0.1, num_iters=iterationCount)\t\n",
    "\tmylr.fit(X_train, y_train) \t\t\t\t\t\t\t\t\t# Only use the 80% of the data marked for training, takes a long time\n",
    "\tmylrPredictions = (mylr.predict(X_test) >= 0.5).astype(int) # Use the remaining 20% of the data marked for testing, predict boolean values\n",
    "\t\n",
    "\t# Calculate confusion matrices\n",
    "\tskllr_confMat = metrics.confusion_matrix(y_test, skllrPredictions)\n",
    "\tmylr_confMat = metrics.confusion_matrix(y_test, mylrPredictions)\n",
    "\t\n",
    "\t# Generate classification reports\n",
    "\tskllr_report = metrics.classification_report(y_test, skllrPredictions, target_names=[\"Positive\", \"Negative\"])\n",
    "\tmylr_report = metrics.classification_report(y_test, mylrPredictions, target_names=[\"Positive\", \"Negative\"])\n",
    "\n",
    "\t# Evaluate sklearn model\n",
    "\tprint(f\"Trial {trial + 1} - Sklearn LogisticRegression:\")\n",
    "\tprint(skllr_confMat)\n",
    "\tprint(skllr_report)\n",
    "\n",
    "\t# Evaluate custom model\n",
    "\tprint(f\"Trial {trial + 1} - Custom LogisticRegression:\")\n",
    "\tprint(mylr_confMat)\n",
    "\tprint(mylr_report)\n",
    "\n",
    "\t# Update average confusion matrices\n",
    "\tavgConfusionMatrix_skllr += skllr_confMat\n",
    "\tavgConfusionMatrix_mylr += mylr_confMat\n",
    "\n",
    "# Calculate and print average confusion matrices\n",
    "avgConfusionMatrix_skllr /= trialCount\n",
    "avgConfusionMatrix_mylr /= trialCount\n",
    "\n",
    "# After all trials are completed, print average of the trials\n",
    "print(\"Average Confusion Matrix - Sklearn LogisticRegression:\")\n",
    "print(avgConfusionMatrix_skllr)\n",
    "print(\"Average Confusion Matrix - Custom LogisticRegression:\")\n",
    "print(avgConfusionMatrix_mylr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
