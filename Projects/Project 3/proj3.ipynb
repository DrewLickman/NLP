{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drew Lickman\\\n",
    "CSCI 4820-001\\\n",
    "Project #3\\\n",
    "Due: 10/9/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Usage Disclaimer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon-Based Sentiment Analysis using Custom Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Requirements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "---\n",
    "\n",
    "- Positive words\n",
    "- Negative words\n",
    "- IMDb reviews\n",
    "\n",
    "### Processing\n",
    "---\n",
    "\n",
    "- There are two classifiers\n",
    "\t- Custom Logistic Regression\n",
    "\t- sklearn LogisticRegression\n",
    "- Implement a Python class (CustomLogisticRegression)\n",
    "\t- \\__init\\__(self, learning_rate, num_iters) method\n",
    "\t\t- self.learning_rate\n",
    "\t\t- self.num_iters\n",
    "\t\t- self.weights = None\n",
    "\t\t- self.bias = None\n",
    "\t- sigmoid(z)\n",
    "\t\t- return result\n",
    "\t- fit(X, y)\n",
    "\t\t- Sets weights to correct shape and initializes them to 0\n",
    "\t\t- Applies batch gradient descent to the entire dataset in a loop for num_iters\n",
    "\t- predict(X)\n",
    "\t\t- z = w dot x + b\n",
    "\t\t- return sigmoid(z) \n",
    "\n",
    "### Output\n",
    "---\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown above each cell used to explain each block of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load and preprocess IMDb reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "sentimentWords = []\n",
    "posWords = []\n",
    "negWords = []\n",
    "with open(\"positive-words.txt\", encoding=\"utf-8\") as positivewords:\n",
    "\tlines = positivewords.readlines()\n",
    "\tfor line in lines:\n",
    "\t\tif line[0] != \";\" and line.strip() != '': \n",
    "\t\t\tposWords.append(line.rstrip('\\n'))\n",
    "with open(\"negative-words.txt\", encoding=\"utf-8\") as negativewords:\n",
    "\tlines = negativewords.readlines()\n",
    "\tfor line in lines:\n",
    "\t\tif line[0] != \";\" and line.strip() != '':\n",
    "\t\t\tnegWords.append(line.rstrip('\\n'))\n",
    "sentimentWords = posWords + negWords # Combine positive words and negative words into one array\n",
    "#print(sentimentWords)\n",
    "\n",
    "reviews = []\n",
    "with open(\"imdb_reviews.txt\", encoding=\"utf-8\") as imdbreviews:\n",
    "    lines = imdbreviews.readlines()\n",
    "    for line in lines:\n",
    "        reviews.append(line)\n",
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create Features(X) table and Labels(y) array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[]] \t# Features\n",
    "y = [] \t\t# Labels\n",
    "posCount = 0\n",
    "negCount = 0\n",
    "\n",
    "for review in range(5):\n",
    "\tX.append([])\n",
    "\tfor word in range(len(sentimentWords)):\n",
    "\t\tif sentimentWords[word] in reviews[review]:\n",
    "\t\t\t#print(sentimentWords[word])\n",
    "\t\t\tX[review].append(True)\n",
    "\t\t\tposCount += 1 \t\t\t\t\t\t\t\t# need to adjust this to count positive / negative word\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t# using posWords and negWords so they can be counted\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t# otherwise it will always be 0 in labels\n",
    "\t\telse:\n",
    "\t\t\tX[review].append(False)\n",
    "\t\t\tnegCount += 1\n",
    "\tif posCount >= negCount:\n",
    "\t\ty.append(1)\n",
    "\telse:\n",
    "\t\ty.append(0)\n",
    "\tposCount = 0\n",
    "\tnegCount = 0\n",
    "X.pop() #Remove empty [] at end of X\n",
    "\n",
    "for review in range(len(X)):\n",
    "\tprint(X[review])\n",
    "\tprint(y[review])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomLogisticRegression():\n",
    "\t# Should be 25-30 lines of code\n",
    "\tprint(\"hi\")\n",
    "\tdef __init__(self, learning_rate, num_iters):\n",
    "\t\tprint(\"init\")\n",
    "\t\tself.learning_rate = learning_rate\n",
    "\t\tself.num_iters = num_iters\n",
    "\t\tself.weights = None\n",
    "\t\tself.bias = None\n",
    "\n",
    "\tdef fit(self, X, y):\n",
    "\t\t# Train the model using gradient descent\n",
    "\t\t# X is training features, y is labels\n",
    "\t\t#np.array(X)\n",
    "\t\t#np.array(y)\n",
    "\t\tfeatures = X.shape[1]\n",
    "\t\tself.weights = np.zeros(features)\n",
    "\t\tself.bias = 0\n",
    "\t\t# Sets the weights to the correct shape and initializes them to 0\n",
    "\t\t# Applies batch gradient descent (entire dataset) in a loop for # iterations specified\n",
    "\t\t# Re-initialize weights and bias \n",
    "\t\tprint(\"fit\")\n",
    "\n",
    "\tdef sigmoid(self, x):\n",
    "\t\tprint(\"apply sigmoid to x\")\n",
    "\t\toutput = 1/(1+math.pow((math.e), -x))\n",
    "\t\tprint(\"Sigmoid:\", output)\n",
    "\t\treturn output\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\t\t# Make predictions on test data\n",
    "\t\t# Computes W DOT x + b\n",
    "\t\toutput = np.dot(self.weights, X) + self.bias #might need to swap W X\n",
    "\t\toutput = self.sigmoid(output)\n",
    "\t\t# Convert to binary output\n",
    "\t\toutput = int(output >= 0.5)\n",
    "\t\treturn output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.LogisticRegression(solver='sag', C=0.001, max_iter=500)\n",
    "CustomLogisticRegression(learning_rate=0.1, num_iters=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
