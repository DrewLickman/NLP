{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94a727b",
   "metadata": {},
   "source": [
    "Drew Lickman\n",
    "\n",
    "CSCI 4820-1\n",
    "\n",
    "Project #5\n",
    "\n",
    "Due: 11/19/24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdef41-3485-495c-9361-172cd74aeabb",
   "metadata": {},
   "source": [
    "# BERT Named Entity Recognition Fine Tuning Project Starter Code\n",
    "### Dr. Sal Barbosa, Department of Computer Science, Middle Tennessee State University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b23c7ff9-6894-4417-98e3-f743546e6d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required on TAMU FASTER to be able to pip install packages and download the dataset from Hugging Face\n",
    "import os\n",
    "os.environ['http_proxy'] = 'http://10.72.8.25:8080'\n",
    "os.environ['https_proxy'] = 'http://10.72.8.25:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30529efd-2c95-45db-98e5-1d9d87c95c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip installs - comment out after running the notebook for the first time\n",
    "#!pip install datasets\n",
    "#!pip install evaluate\n",
    "#!pip install seqeval\n",
    "#!pip install accelerate==0.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f508615-b7a1-4962-ad3c-298ede099e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 20:28:18.454648: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-16 20:28:20.627867: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-16 20:28:20.627907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-16 20:28:20.642030: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-16 20:28:21.501427: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-16 20:28:25.126465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, DatasetDict, Sequence, ClassLabel\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9030258-084f-44ff-ae21-0321302ffeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CONLL-2003 NER dataset\n",
    "dataset = load_dataset(\"conll2003\")\n",
    "\n",
    "# Remove columns not used in this code\n",
    "dataset = dataset.remove_columns(['id', 'pos_tags', 'chunk_tags'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3041a113-2e7d-4691-be22-30b79bef7078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label list: ['O', 'B-MPER', 'I-MPER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-FPER', 'I-FPER']\n"
     ]
    }
   ],
   "source": [
    "# Get and display the NER tag list for the dataset\n",
    "label_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "# Rename PERSON labels to MALE labels\n",
    "label_list[1] = 'B-MPER'\n",
    "label_list[2] = 'I-MPER'\n",
    "\n",
    "# Append FEMALE labels at end of label list\n",
    "label_list.append('B-FPER')\n",
    "label_list.append('I-FPER')\n",
    "\n",
    "print(\"Label list:\", label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40342865-4e3e-4616-8b76-8a5f212e05bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u.al234966/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT cased model\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89b56bf5-d3e0-41eb-adc2-bab03c12e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isShortNonsense(token):\n",
    "    # Removes tokens such as \"M.\" \"S.\" \"R.\" etc. from being male or female\n",
    "    if len(token) == 2 and token[-1] == '.':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Some names came from https://nameberry.com/blog/the-most-popular-baby-name-endings 11/15/24\n",
    "femaleWhole = (\"Taha\", \"Olga\", \"Andi\", \"Inga\", \"Abu\", \"Mia\", \"Rui\", \"Kim\", \"Ai\", \"Ebe\", \"Ruth\")\n",
    "femaleBeginnings = (\"ali\", \"van\", \"giu\", \"anne\", \"mus\", \"ove\", \"iva\", \"wits\", \"kusu\", \"marie\", \"est\", \"tuli\", \"soe\", \"mary\", \"las\", \"piz\", \"kord\", \"asan\", \"flo\", \"xia\", \"ovi\", \"mont\", \"yal\", \"gen\", \"tan\", \"harb\", \"pica\", \"kat\", \"bh\", \"wie\", \"gwe\", \"heal\", \"hild\", \"alic\", \"ott\", \"eki\", \"hos\", \"pud\", \"sara\", \"male\", \"nai\", \"jee\", \"lea\", \"ciri\", \"paol\", \"mere\", \"lind\", \"bai\", \"chi\", \"olivi\", \"cha\", \"eyl\", \"zun\", \"lore\", \"tara\", \"ise\", \"woo\", \"pet\", \"gius\", \"cook\", \"fab\", \"ghe\", \"syb\", \"juh\", \"bell\", \"charli\", \"asi\", \"lie\", \"chiq\", \"duf\", \"yas\", \"zit\", \"may\", \"kimi\", \"joha\", \"ili\", \"luo\", \"viv\", \"hill\", \"min\", \"marg\", \"till\")\n",
    "femaleEndings = (\"ati\", \"lde\", \"sca\", \"esa\", \"rla\", \"tea\", \"anni\", \"une\", \"nzu\", \"bel\", \"bell\", \"aoui\", \"tti\", \"kat\", \"sza\", \"ski\", \"cia\", \"de\", \"fer\", \"nose\", \"ess\", \"ya\", \"ith\", \"cis\", \"ska\", \"hge\", \"nga\", \"uska\", \"urin\", \"ero\", \"sey\", \"dia\", \"eri\", \"rle\", \"fje\", \"rey\", \"shi\", \"tia\", \"nne\", \"rie\", \"chua\", \"oke\", \"gan\", \"uu\", \"ala\", \"hai\", \"ura\", \"oki\", \"ude\", \"ehe\", \"ada\", \"nez\", \"uya\", \"nka\", \"ake\", \"lin\", \"isa\", \"jup\", \"guz\", \"ail\", \"uil\", \"ief\", \"ail\", \"lyn\", \"rgy\", \"erin\", \"oan\", \"cin\", \"ncy\", \"ace\", \"ssa\", \"sea\", \"air\", \"kim\", \"oao\", \"hild\", \"ppo\", \"nes\", \"ble\", \"tja\", \"slaw\", \"amm\", \"aly\", \"ely\", \"aish\", \"ooch\", \"sta\", \"nge\", \"ilo\", \"nna\", \"rel\", \"lva\", \"dle\", \"awa\", \"na\", \"ila\", \"piot\", \"fah\", \"ffel\", \"asa\", \"lle\", \"aas\", \"adi\", \"tta\", \"miya\", \"buza\", \"vai\", \"udi\", \"ita\", \"ira\", \"aga\", \"ami\", \"ica\", \"igi\", \"ori\", \"cre\", \"nda\", \"era\", \"icky\", \"iya\", \"yste\", \"li\", \"dea\", \"ha\", \"cu\", \"uc\", \"eah\", \"ure\", \"ate\", \"oche\", \"tel\", \"ele\", \"ee\", \"chi\", \"eva\", \"karo\", \"eggy\", \"via\", \"ama\", \"eles\", \"ope\", \"ela\", \"ona\", \"anda\", \"rii\", \"lly\", \"lli\", \"nja\", \"oku\", \"weyi\", \"sha\", \"aki\", \"pese\", \"alo\", \"tra\", \"elo\", \"rpe\", \"oto\", \"omo\", \"osa\", \"ghe\", \"ini\", \"rei\", \"are\", \"mmi\", \"ena\", \"luca\", \"thia\", \"una\", \"lah\", \"ewa\", \"aba\", \"eira\", \"aan\", \"gle\", \"xei\", \"eve\", \"erre\", \"wicz\", \"issa\", \"lat\", \"ima\", \"uta\", \"ley\", \"xia\", \"oe\", \"que\", \"nia\", \"hia\", \"iza\", \"erly\", \"ean\", \"ylis\", \"iew\", \"wicz\", \"issy\", \"dra\", \"abi\", \"rta\", \"aya\", \"gato\", \"cca\", \"oko\", \"gma\", \"ika\", \"ay\", \"ies\", \"zio\", \"arda\", \"oux\", \"ore\", \"elli\", \"raj\", \"antha\", \"gne\", \"kki\", \"evic\", \"ino\", \"ata\", \"ene\", \"si\", \"az\", \"uki\", \"ise\", \"ova\", \"oin\", \"ria\", \"ata\", \"anne\", \"drea\", \"ayla\", \"essa\", \"her\", \"anna\", \"ana\", \"ette\", \"etta\", \"elle\", \"ella\", \"ina\", \"yah\", \"iah\", \"lyn\", \"icia\", \"rie\", \"ora\", \"lie\", \"thy\", \"atie\", \"rude\", \"lia\", \"lla\", \"enna\", \"ine\", \"ani\", \"ola\", \"een\", \"ahi\", \"kie\", \"ane\", \"ahu\", \"ara\", \"ari\", \"mbe\", \"pta\", \"ady\", \"ie\", \"ary\", \"xa\")\n",
    "def is_female_name(token):\n",
    "    # Uses algorithmic approach to assign gender tag and returns boolean\n",
    "    result = False\n",
    "    #if any(token.lower().endswith(ending) for ending in femaleEndings):\n",
    "    if token.lower().endswith(femaleEndings):\n",
    "        result = True\n",
    "    #elif any(token.lower().startswith(start) for start in femaleBeginnings):\n",
    "    elif token.lower().startswith(femaleBeginnings):\n",
    "        result = True\n",
    "    elif token in femaleWhole:\n",
    "        result = True\n",
    "    #if result: print(\"F:\",token)\n",
    "    return result\n",
    "\n",
    "maleWhole = (\"Jimi\", \"Levy\", \"Sammy\", \"Anders\", \"Jens\", \"Andy\", \"Fred\", \"Nick\", \"Juan\", \"Kenny\", \"Abu\", \"Jay\", \"Tim\", \"Roy\", \"Danny\", \"Liam\", \"Alex\", \"Shen\", \"Costas\", \"Dan\", \"Hal\", \"Sam\", \"Tom\", \"Ken\", \"Daniel\", \"Ian\", \"Blake\")\n",
    "maleBeginnings = (\"man\", \"mr\", \"vas\", \"narc\", \"kafel\", \"tom\", \"tavar\", \"gab\", \"bug\", \"wid\", \"uly\", \"dem\", \"jong\", \"lloy\", \"gro\", \"wes\", \"shad\", \"adol\", \"kev\", \"sul\", \"glen\", \"jet\", \"swi\", \"mc\", \"rang\", \"domi\", \"jont\", \"gram\", \"belm\", \"virg\", \"sme\", \"wij\", \"oti\", \"rock\", \"clem\", \"des\", \"sobo\", \"hin\", \"ban\", \"banh\", \"ham\", \"ahm\", \"smy\", \"simo\", \"dro\", \"jar\", \"rai\", \"grz\", \"frit\", \"shkv\", \"fed\", \"orr\", \"korn\", \"sore\", \"nil\", \"die\", \"mur\", \"lan\", \"parn\", \"ant\", \"maur\", \"cy\", \"arn\", \"grae\", \"lew\", \"take\", \"rub\", \"rifk\", \"rugg\", \"hers\", \"hars\", \"agr\", \"arj\", \"max\", \"kar\", \"gran\", \"li\", \"mosh\", \"ed\", \"rip\", \"ren\", \"jan\", \"chris\", \"neal\", \"hu\", \"marc\", \"you\", \"mill\", \"arw\", \"jul\", \"fern\", \"shig\", \"feli\", \"hidem\", \"stew\", \"serg\", \"efa\", \"jose\", \"olin\", \"erik\", \"bry\", \"sato\", \"jone\", \"fred\", \"owen\", \"edb\", \"bena\", \"web\", \"mach\", \"jim\", \"jord\", \"elm\", \"huse\", \"kenn\", \"vog\", \"jeff\", \"buca\", \"Yon\", \"craw\", \"bur\", \"charle\", \"tho\", \"aa\", \"col\", \"kri\", \"javi\", \"moy\", \"hic\", \"gar\", \"hunt\", \"cor\", \"bill\", \"bob\", \"hel\", \"will\", \"mick\", \"con\", \"sal\", \"ric\", \"phi\", \"terr\", \"bru\", \"pete\", \"shay\", \"wern\", \"nikol\", \"fisch\", \"skandal\", \"stef\", \"benj\", \"rabi\", \"must\", \"per\", \"core\", \"dal\", \"gor\", \"pav\", \"coop\", \"ross\", \"car\", \"kaz\", \"bor\", \"asl\", \"bert\", \"cli\", \"stev\", \"pres\", \"berr\", \"greg\")\n",
    "maleEndings = (\".\", \"drew\", \"ner\", \"guez\", \"ula\", \"ent\", \"ciso\", \"gno\", \"ust\", \"hon\", \"vio\", \"sch\", \"hul\", \"dov\", \"mme\", \"ret\", \"len\", \"ges\", \"colm\", \"rris\", \"hin\", \"itis\", \"ens\", \"emy\", \"nco\", \"alf\", \"kov\", \"taro\", \"ngo\", \"sma\", \"sby\", \"hrs\", \"rko\", \"cot\", \"irk\", \"els\" \"age\", \"abe\", \"non\", \"art\", \"hty\", \"led\", \"pat\", \"dlen\", \"unt\", \"tan\", \"blo\", \"him\", \"ahl\", \"dev\", \"dis\", \"pol\", \"uet\", \"lor\", \"ksy\", \"kian\", \"nty\", \"cins\", \"jan\", \"trv\", \"rdt\", \"ulz\", \"zon\", \"onk\", \"can\", \"erg\", \"ome\", \"rik\", \"tof\", \"agg\", \"rke\", \"ist\", \"sus\", \"ved\", \"rag\", \"ke\", \"mens\", \"man\", \"men\", \"eck\", \"rry\", \"ryn\", \"kol\", \"dar\", \"del\", \"yev\", \"nsu\", \"kh\", \"nic\", \"rel\", \"ifo\", \"kow\", \"uin\", \"ers\", \"nah\", \"har\", \"gram\", \"khar\", \"hd\", \"dam\", \"dams\", \"erd\", \"gis\", \"acky\", \"ser\", \"yss\", \"rts\", \"nds\", \"med\", \"tz\", \"orz\", \"ndes\", \"uke\", \"ato\", \"yrin\", \"alk\", \"uus\", \"nck\", \"own\", \"klin\", \"dys\", \"rer\", \"hev\", \"ker\", \"esse\", \"oen\", \"ego\", \"iano\", \"ney\", \"wey\", \"geny\", \"lis\", \"nio\", \"icio\", \"lch\", \"raf\", \"yuk\", \"hen\", \"aud\", \"mura\", \"nan\", \"nny\", \"kob\", \"link\", \"rett\", \"andy\", \"aus\", \"cois\", \"kis\", \"ink\", \"ur\", \"ind\", \"ath\", \"ndt\", \"sco\", \"ler\", \"ewt\", \"iser\", \"ein\", \"wis\", \"ind\", \"ien\", \"vik\", \"att\", \"orm\", \"nis\", \"reas\", \"zen\", \"las\", \"cak\", \"sty\", \"ats\", \"vin\", \"lip\", \"nko\", \"ons\", \"ume\", \"tien\", \"iri\", \"ij\", \"ant\", \"cisco\", \"rst\", \"ken\", \"tian\", \"nas\", \"slav\", \"wel\", \"ando\", \"han\", \"lix\", \"wart\", \"gen\", \"rif\", \"emp\", \"ruw\", \"ryan\", \"one\", \"yan\", \"wire\", \"pot\", \"lan\", \"olf\", \"gel\", \"ber\", \"dim\", \"tar\", \"red\", \"borg\", \"scar\", \"naj\", \"eir\", \"iki\", \"man\", \"ven\", \"un\", \"rek\", \"ric\", \"kus\", \"ten\", \"ito\", \"ite\", \"tro\", \"erve\", \"ido\", \"nna\", \"ster\", \"aac\", \"old\", \"ean\", \"eil\", \"rren\", \"gts\", \"orn\", \"roy\", \"les\", \"rio\", \"ter\", \"ral\", \"mond\", \"sen\", \"wan\", \"ado\", \"rak\", \"nn\", \"hew\", \"ier\", \"ike\", \"rgi\", \"vanni\", \"bed\", \"sin\", \"ald\", \"ole\", \"eus\", \"req\", \"chez\", \"nen\", \"ich\", \"pov\", \"nov\", \"dre\", \"mir\", \"erry\", \"ght\", \"lock\", \"utch\", \"os\", \"chel\", \"oel\", \"ert\", \"arl\", \"ger\", \"ald\", \"eld\", \"ford\", \"ques\", \"ott\", \"ham\", \"vic\", \"oft\", \"ump\", \"ance\", \"ius\", \"tor\", \"orge\", \"uis\", \"monn\", \"mir\", \"uzo\", \"oug\", \"ock\", \"ado\", \"dro\", \"tor\", \"nce\", \"cer\", \"hris\", \"iel\", \"ave\", \"ek\", \"mann\", \"tr\", \"din\", \"dan\", \"ung\", \"al\", \"aul\", \"mir\", \"nry\", \"rty\", \"ldo\", \"ack\", \"ver\", \"gos\", \"olas\", \"cott\", \"ard\", \"rco\", \"dict\", \"udan\", \"mut\", \"rnd\", \"vis\", \"ael\", \"yne\", \"ng\", \"ick\", \"oud\", \"ard\", \"onan\", \"kel\", \"ayne\", \"git\", \"eer\", \"son\", \"ank\", \"unk\", \"ion\", \"oey\", \"mes\", \"ll\", \"than\", \"hn\", \"rick\", \"tn\", \"eg\", \"nley\", \"uce\", \"ndon\", \"osh\", \"ony\", \"even\", \"odd\", \"drix\", \"ang\", \"vid\", \"yahu\", \"san\", \"afat\", \"abil\", \"anz\", \"ain\", \"itris\", \"rner\", \"hael\", \"rtin\", \"taq\", \"eed\", \"haq\", \"asim\", \"mad\", \"ncan\", \"aig\", \"nto\", \"vich\", \"od\", \"mon\", \"der\", \"rad\", \"ting\", \"bert\", \"imis\", \"ran\", \"ark\", \"dul\", \"uy\", \"ippe\", \"mas\", \"nus\", \"cil\", \"vey\", \"los\", \"nup\", \"van\", \"uel\", \"ff\", \"rim\", \"pras\", \"dric\", \"uck\", \"ox\", \"vit\", \"jon\", \"ron\", \"rian\", \"ton\", \"dam\", \"rri\", \"sky\", \"fez\", \"mar\", \"sad\", \"tin\", \"usz\", \"qar\", \"rto\", \"ory\")\n",
    "def is_male_name(token):\n",
    "    # Uses algorithmic approach to assign gender tag and returns boolean\n",
    "    result = False\n",
    "    #if any(token.lower().endswith(ending) for ending in maleEndings):\n",
    "    if token.lower().endswith(maleEndings):\n",
    "        result = True\n",
    "    #elif any(token.lower().startswith(start) for start in maleBeginnings):\n",
    "    elif token.lower().startswith(maleBeginnings):\n",
    "        result = True\n",
    "    elif token in maleWhole:\n",
    "        result = True\n",
    "    #if result: print(\"M:\",token)\n",
    "    return result\n",
    "\n",
    "def chooseGender(femResult, maleResult):\n",
    "\t# If I use weights (instead of booleans), I can compare\n",
    "\tresult = femResult - maleResult\n",
    "\tif result >= 0:\n",
    "\t\treturn \"Female\"\n",
    "\telse:\n",
    "\t\treturn \"Male\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "066a7e95-313b-4374-acfa-eeb617a403f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfea13a38af4f5aa65bc489e7a16498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ferenc\n",
      "Mo\n",
      "Malu\n",
      "Ro\n",
      "Qian\n",
      "Said\n",
      "Said\n",
      "Lou\n",
      "Hans-Otto\n",
      "Inderjit\n",
      "Saint\n",
      "Teresa\n",
      "Therese\n",
      "Leonid\n",
      "Kuchma\n",
      "Kuchma\n",
      "Kuchma\n",
      "Dmitry\n",
      "Akram\n",
      "Davenport\n",
      "Davenport\n",
      "Jacob\n",
      "Haile\n",
      "Wilmots\n",
      "Nicoleta\n",
      "Dawn\n",
      "Emilio\n",
      "Paula\n",
      "Sinead\n",
      "Moses\n",
      "Gideon\n",
      "Larbi\n",
      "Eliud\n",
      "Lamont\n",
      "Maicel\n",
      "Khalid\n",
      "El\n",
      "Lars\n",
      "Vaclavas\n",
      "Sigurd\n",
      "Elijah\n",
      "Laban\n",
      "Aloys\n",
      "Mathias\n",
      "Worku\n",
      "Paulo\n",
      "Paulinho\n",
      "Oceano\n",
      "Matthias\n",
      "Matthias\n",
      "Mehmet\n",
      "Cam\n",
      "Batterby\n",
      "Buffett\n",
      "Buffett\n",
      "Buffett\n",
      "Sameh\n",
      "Sameh\n",
      "Tungky\n",
      "Don\n",
      "Curtis\n",
      "Tracy\n",
      "Tracy\n",
      "Roosevelts\n",
      "Prakash\n",
      "Munakarmi\n",
      "Erbakan\n",
      "Nacar\n",
      "Rob\n",
      "Tuan\n",
      "Costis\n",
      "Costis\n",
      "Amer\n",
      "Ukyo\n",
      "Sigeki\n",
      "Joost\n",
      "Zinzan\n",
      "Joost\n",
      "Zinzan\n",
      "Zinzan\n",
      "Romeo\n",
      "Enzo\n",
      "Debbah\n",
      "Guivarc'h\n",
      "Wreh\n",
      "Votava\n",
      "Schwabl\n",
      "Zorc\n",
      "Zeyer\n",
      "Gaissmayer\n",
      "Penrose\n",
      "Penrose\n",
      "Penrose\n",
      "Damian\n",
      "Kamuzu\n",
      "Firmin\n",
      "Gcaleka\n",
      "Gcaleka\n",
      "Servet\n",
      "Violeta\n",
      "Khemais\n",
      "Majid\n",
      "Ignacio\n",
      "Bourlet\n",
      "An\n",
      "An\n",
      "An\n",
      "Brooks\n",
      "Pierre-Henri\n",
      "Jean-Marc\n",
      "Belim\n",
      "Ruch\n",
      "Raphanel\n",
      "Sarka\n",
      "Deon\n",
      "Gillian\n",
      "Trond\n",
      "Ukyo\n",
      "Wataru\n",
      "Norihiko\n",
      "Takuma\n",
      "Ryo\n",
      "Takuma\n",
      "Ryo\n",
      "Wataru\n",
      "Takuma\n",
      "Byas\n",
      "Solskjaer\n",
      "Alec\n",
      "Alec\n",
      "Bartlomiej\n",
      "Srutwa\n",
      "Yap\n",
      "Lotte\n",
      "Lotte\n",
      "Lotte\n",
      "Kyle\n",
      "Palmeiro\n",
      "Dante\n",
      "Kurt\n",
      "Andrejez\n",
      "Rodrigo\n",
      "Paulao\n",
      "Idalecio\n",
      "Batigol\n",
      "Ernest\n",
      "Romano\n",
      "Zeljko\n",
      "Erwin\n",
      "Wouden\n",
      "SIDHU\n",
      "Navjot\n",
      "Sidhu\n",
      "Sidhu\n",
      "Sidhu\n",
      "Zinzan\n",
      "Thabo\n",
      "Tutu\n",
      "Tutu\n",
      "Currin\n",
      "Currin\n",
      "Reuf\n",
      "Anatoly\n",
      "Vicente\n",
      "Seneferu\n",
      "Shabir\n",
      "Kabariti\n",
      "Ezer\n",
      "Aryeh\n",
      "Shumer\n",
      "Ezer\n",
      "Bourlet\n",
      "Bourlet\n",
      "Bourlet\n",
      "Bourlet\n",
      "Bourlet\n",
      "Juppe\n",
      "Dostum\n",
      "Hekmatyar\n",
      "Jumbish\n",
      "Rafiqul\n",
      "Begum\n",
      "Odnosum\n",
      "Odnosum\n",
      "Odnosum\n",
      "Sainz\n",
      "Kapil\n",
      "Bachirou\n",
      "Rimma\n",
      "Coetzer\n",
      "Coetzer\n",
      "Yi\n",
      "Jaime\n",
      "Yi\n",
      "Els\n",
      "Trenidad\n",
      "Jody\n",
      "Wim\n",
      "Jaap\n",
      "Wim\n",
      "Pantic\n",
      "Streak\n",
      "Streak\n",
      "Shah\n",
      "Hogg\n",
      "Hogg\n",
      "Hogg\n",
      "Kurt\n",
      "Agota\n",
      "Regula\n",
      "Vega\n",
      "Alonso\n",
      "Violeta\n",
      "Amr\n",
      "Strobe\n",
      "Daschle\n",
      "Daschle\n",
      "Lelouche\n",
      "Lelouche\n",
      "Nadarajah\n",
      "Watts\n",
      "Sudradjat\n",
      "Kostas\n",
      "Leon\n",
      "Boeta\n",
      "Alec\n",
      "Rashid\n",
      "Cozma\n",
      "Danut\n",
      "Cozma\n",
      "Cozma\n",
      "Lupu\n",
      "Cozma\n",
      "Lupu\n",
      "Lupu\n",
      "Cozma\n",
      "Cozma\n",
      "Ben\n",
      "Laxmi\n",
      "Jacob\n",
      "Radka\n",
      "Pam\n",
      "Tamer\n",
      "Amy\n",
      "Miriam\n",
      "Radka\n",
      "Andres\n",
      "Royce\n",
      "Mo\n",
      "Jaime\n",
      "Coetzer\n",
      "Tretschok\n",
      "Roest\n",
      "Wouden\n",
      "Teemu\n",
      "Jyrki\n",
      "Claudio\n",
      "Wim\n",
      "Emese\n",
      "Erdei\n",
      "Erdei\n",
      "Sitanyi\n",
      "Curtis\n",
      "Lynch\n",
      "Caesar\n",
      "Dmitry\n",
      "Nastase\n",
      "Funar\n",
      "An\n",
      "Lambrecks\n",
      "An\n",
      "SAO\n",
      "Schutte\n",
      "Schutte\n",
      "SAO\n",
      "Havel\n",
      "Vaclav\n",
      "Havel\n",
      "Vicente\n",
      "Leon\n",
      "Juppe\n",
      "Rupam\n",
      "Das\n",
      "Sayed\n",
      "Hekmatyar\n",
      "Khum\n",
      "Khadga\n",
      "Khadga\n",
      "Choudhury\n",
      "Choudhury\n",
      "Begum\n",
      "Peiris\n",
      "Peiris\n",
      "North\n",
      "Kan\n",
      "Sheu\n",
      "Sheu\n",
      "Don\n",
      "Emilio\n",
      "Lauren\n",
      "Cevaer\n",
      "Brenden\n",
      ".Giuseppe\n",
      "Kaspars\n",
      "Kaspars\n",
      "Heiko\n",
      "Ainars\n",
      "Keiji\n",
      "Kurt\n",
      "J\n",
      "Heiko\n",
      "Hideo\n",
      "Devon\n",
      "Devon\n",
      "Zinzan\n",
      "Robin\n",
      "Olo\n",
      "BONNET\n",
      "Bonnet\n",
      "GIBBS\n",
      "Gibbs\n",
      "Gibbs\n",
      "Yuri\n",
      "Amr\n",
      "Faheem\n",
      "Courtois\n",
      "Hristo\n",
      "Pantic\n",
      "Vicente\n",
      "Hristo\n",
      "Enrico\n",
      "Arrigo\n",
      "Paulo\n",
      "Von\n",
      "Enzo\n",
      "Patrice\n",
      "Pires\n",
      "Aime\n",
      "Pires\n",
      "Patrice\n",
      "Benoit\n",
      "Leonardo\n",
      "Vierklau\n",
      "Roest\n",
      "Wouden\n",
      "Lefevre\n",
      "Pires\n",
      "Rouxel\n",
      "Guivarch\n",
      "TENDULKAR\n",
      "Romesh\n",
      "Tendulkar\n",
      "Tendulkar\n",
      "Tendulkar\n",
      "Tendulkar\n",
      "Tendulkar\n",
      "Kapoor\n",
      "Jadeja\n",
      "Ganguly\n",
      "Anil\n",
      "Sourav\n",
      "Venkatesh\n",
      "Ashish\n",
      "Romesh\n",
      "Napoleon\n",
      "Geronimo\n",
      "Todor\n",
      "Henri\n",
      "Remmy\n",
      "Alhadji\n",
      "An\n",
      "Agnieszka\n",
      "Jerzy\n",
      "Shehu\n",
      "Kohl\n",
      "Kohl\n",
      "Adem\n",
      "Bernardo\n",
      "Arce\n",
      "Ernesto\n",
      "Samper\n",
      "Samper\n",
      "Samper\n",
      "Pelletreau\n",
      "Nsanze\n",
      "Bose\n",
      "Adelt\n",
      "Wafa\n",
      "Yitzhak\n",
      "Omer\n",
      "Romano\n",
      "Omer\n",
      "Prodi\n",
      "Head\n",
      "Gale\n",
      "Juppe\n",
      "Juppe\n",
      "Reppas\n",
      "Reppas\n",
      "Weiss\n",
      "Weiss\n",
      "Ta\n",
      "Kubo\n",
      "Wataru\n",
      "Kubo\n",
      "Kubo\n",
      "Kubo\n",
      "Kubo\n",
      "Yukio\n",
      "Dai\n",
      "Dai\n",
      "Dai\n",
      "Hwa\n",
      "Nahed\n",
      "Aleix\n",
      "Wilfried\n",
      "Voskamp\n",
      "Olaf\n",
      "Moreau\n",
      "Anwar\n",
      "Gough\n",
      "Gough\n",
      "Gough\n",
      "LOMBARDI\n",
      "Hans\n",
      "Servais\n",
      "Olaf\n",
      "Lombardi\n",
      "Den\n",
      "Alec\n",
      "Hans\n",
      "Amr\n",
      "Els\n",
      "Miriam\n",
      "Amy\n",
      "Don\n",
      "Baldwin\n",
      "Tauziat\n",
      "Ferdy\n",
      "Yoka\n",
      "Mobutu\n",
      "Mobutu\n",
      "Ikimi\n",
      "Ikimi\n",
      "Beatrix\n",
      "Beatrix\n",
      "Idriss\n",
      "Deby\n",
      "Deby\n",
      "Henri\n",
      "Artyom\n",
      "Aguirre\n",
      "SAO\n",
      "Lucas\n",
      "Andrews\n",
      "Andrews\n",
      "Shahid\n",
      "Justice\n",
      "R\n",
      "Elias\n",
      "Kan\n",
      "Patsy\n",
      "Kabariti\n",
      "Kabariti\n",
      "Kabariti\n",
      "Kabariti\n",
      "Kabariti\n",
      "Kabariti\n",
      "Budge\n",
      "Santa\n",
      "Nitto\n",
      "Ilkka\n",
      "Joyce\n",
      "Ingrid\n",
      "Ingrid\n",
      "Agnieszka\n",
      "Norifumi\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15904d6704c440099d1bca8508d3eb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Such\n",
      "Teddy\n",
      "Cosmin\n",
      "Anatoly\n",
      "Camacho\n",
      "Jesper\n",
      "Russ\n",
      "Jesper\n",
      "Gillian\n",
      "Emilio\n",
      "Astrid\n",
      "Venuste\n",
      "Laban\n",
      "Lars\n",
      "Gete\n",
      "Rose\n",
      "Tegla\n",
      "Nico\n",
      "Adem\n",
      "Igor\n",
      "Maksim\n",
      "Igor\n",
      "Dmitri\n",
      "El\n",
      "Shem\n",
      "Sigurd\n",
      "Oeji\n",
      "Bisconti\n",
      "Law\n",
      "Waugh\n",
      "Romesh\n",
      "Upul\n",
      "Irwin\n",
      "Harte\n",
      "Townsend\n",
      "Nagoum\n",
      "Amra\n",
      "Semyon\n",
      "Yuri\n",
      "Sherbatov\n",
      "Rajab\n",
      "Valery\n",
      "Emese\n",
      "Norodom\n",
      "Sihanouk\n",
      "Sihanouk\n",
      "Norodom\n",
      "Gaddafi\n",
      "Samer\n",
      "Gaddafi\n",
      "Gaddafi\n",
      "Gaddafi\n",
      "Yitzhak\n",
      "Ezer\n",
      "Juppe\n",
      "Juppe\n",
      "Kamil\n",
      "Jamil\n",
      "Jamil\n",
      "Ralph\n",
      "Paula\n",
      "Lex\n",
      "Vafa\n",
      "Zhirayr\n",
      "Stig\n",
      "Heidi\n",
      "Wahono\n",
      "Tono\n",
      "Augusto\n",
      "Haim\n",
      "Nir\n",
      "Allenby\n",
      "Olaf\n",
      "Jesper\n",
      "Ludwig\n",
      "Skibby\n",
      "Gough\n",
      "Gough\n",
      "Gough\n",
      "Gough\n",
      "Lucy\n",
      "Heiko\n",
      "Wendy\n",
      "Ainars\n",
      "Lucy\n",
      "Mazeikyte\n",
      "Alec\n",
      "GONZALEZ\n",
      "Gonzalez\n",
      "Gonzalez\n",
      "Gonzalez\n",
      "Gonzalez\n",
      "Darryl\n",
      "Robin\n",
      "Buddy\n",
      "LYNAGH\n",
      "Lynagh\n",
      "Lynagh\n",
      "Gil\n",
      "Joost\n",
      "Joost\n",
      "Kobus\n",
      "Zinzan\n",
      "Robin\n",
      "Olo\n",
      "Joost\n",
      "Jesper\n",
      "Jasper\n",
      "Kraft\n",
      "Davenport\n",
      "Joe-Max\n",
      "Devon\n",
      "Bolesy\n",
      "(\n",
      "(\n",
      "Shawn\n",
      "Alvaro\n",
      "NASEEM\n",
      "Naseem\n",
      "Herfried\n",
      "Aime\n",
      "Leboeuf\n",
      "Ouedec\n",
      "Ouedec\n",
      "Sabri\n",
      "Bixente\n",
      "Patrice\n",
      "Alfonso\n",
      "Claudio\n",
      "Duilio\n",
      "Becerril\n",
      "Gomez\n",
      "Cuauhtemoc\n",
      "Rustu\n",
      "Degryse\n",
      "Nico\n",
      "Enzo\n",
      "Rustu\n",
      "Hakan\n",
      "Recep\n",
      "Hakan\n",
      "Saffet\n",
      "Wilfried\n",
      "Miss\n",
      "Paddy\n",
      "Cosmin\n",
      "Elizabeth\n",
      "Kutuzov\n",
      "Napoleon\n",
      "Napoleon\n",
      "Trevor\n",
      "Holland\n",
      "Holland\n",
      "Mubatik\n",
      "Mouldi\n",
      "Puig\n",
      "Puig\n",
      "Fulgencio\n",
      "Puig\n",
      "Puig\n",
      "SANTIAGO\n",
      "Deborah\n",
      "Win\n",
      "Hla\n",
      "Faik\n",
      "Aziz\n",
      "Aziz\n",
      "Aziz\n",
      "Habib\n",
      "Don\n",
      "Nyerere\n",
      "Nyerere\n",
      "Nyerere\n",
      "Nyerere\n",
      "Mao\n",
      "Yitzak\n",
      "Kitty\n",
      "Shakil\n",
      "Khurshid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f6aeada9c84dfdaa0fe7e3072367d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Igor\n",
      "Hiroshige\n",
      "Shu\n",
      "Coste\n",
      "Coste\n",
      "Coste\n",
      "Massimo\n",
      "Massimo\n",
      "Takagi\n",
      "Hiroshige\n",
      "Motohiro\n",
      "Masakiyo\n",
      "Nihad\n",
      "Jesper\n",
      "Candice\n",
      "Tae\n",
      "Zahoor\n",
      "Cairns\n",
      "Inzamamul\n",
      "Astle\n",
      "Shahid\n",
      "Astle\n",
      "Cairns\n",
      "Astle\n",
      "Afridi\n",
      "Afridi\n",
      "Shahid\n",
      "BOWYER\n",
      "Bowyer\n",
      "Bowyer\n",
      "Bowyer\n",
      "Rob\n",
      "Campo\n",
      "Rob\n",
      "Rob\n",
      "Botes\n",
      "Trevor\n",
      "Don\n",
      "Anghel\n",
      "Tibor\n",
      "Iulian\n",
      "Basarab\n",
      "Dorinel\n",
      "Ionel\n",
      "Blewett\n",
      "Warne\n",
      "Moody\n",
      "Blewett\n",
      "Moody\n",
      "Blewett\n",
      "Warne\n",
      "Warne\n",
      "Moody\n",
      "Blewett\n",
      "Warne\n",
      "Hooper\n",
      "Hooper\n",
      "Ambrose\n",
      "Walsh\n",
      "Hooper\n",
      "Sherwin\n",
      "Junior\n",
      "Nixon\n",
      "Curtly\n",
      "Roland\n",
      "Rashid\n",
      "Ye\n",
      "Ye\n",
      "Faulk\n",
      "Kerwin\n",
      "Faulk\n",
      "Ty\n",
      "Japhet\n",
      "Gourvennec\n",
      "Stickroth\n",
      "Wosz\n",
      "Ramelow\n",
      "Georg\n",
      "Paulinho\n",
      "Oceano\n",
      "Paulo\n",
      "Paulo\n",
      "Davor\n",
      "Guillermo\n",
      "Amor\n",
      "AbelardoFernandez\n",
      "Chendo\n",
      "Igor\n",
      "Fausto\n",
      "Joceyln\n",
      "Harper\n",
      "Nicol\n",
      "Nicol\n",
      "Nicol\n",
      "DURBAN\n",
      "HAVEL\n",
      "Vaclav\n",
      "Havel\n",
      "Havel\n",
      "Havel\n",
      "Havel\n",
      "Emil\n",
      "Zieleniec\n",
      "Vaclav\n",
      "Zieleniec\n",
      "Alfonse\n",
      "HAVEL\n",
      "Vaclav\n",
      "Havel\n",
      "Havel\n",
      "Havel\n",
      "Havel\n",
      "Major\n",
      "Major\n",
      "Major\n",
      "Sherwin\n",
      "Baril\n",
      "Baril\n",
      "Baril\n",
      "Abdou\n",
      "Diouf\n",
      "Diouf\n",
      "Patasse\n",
      "Patasse\n",
      "Patasse\n",
      "Patasse\n",
      "Patasse\n",
      "Patasse\n",
      "Baruch\n",
      "Qazim\n",
      "Igor\n",
      "Yegor\n",
      "Sandor\n",
      "Sandor\n",
      "Greenspan\n",
      "Greenspan\n",
      "Greenspan\n",
      "Farid\n",
      "Hakme\n",
      "Ivo\n",
      "Hakme\n",
      "SANTIAGO\n",
      "Aninat\n",
      "Aninat\n",
      "Aninat\n",
      "Alatas\n",
      "Alatas\n",
      "Alatas\n",
      "Alatas\n",
      "Kohl\n",
      "Vithoon\n",
      "Note\n",
      "Takao\n",
      "Saqr\n",
      "Voeks\n",
      "Voeks\n",
      "Voeks\n",
      "H\n",
      "Don\n",
      "Kofi\n",
      "Santa\n",
      "Santa\n",
      "Saint\n",
      "Major\n",
      "Major\n",
      "Major\n",
      "Major\n",
      "Major\n",
      "Snow\n",
      "Snow\n",
      "Rashid\n",
      "Rashid\n",
      "Rashid\n",
      "Rashid\n",
      "Rashid\n",
      "Rashid\n",
      "Elif\n",
      "Benchaou\n",
      "Benchaou\n",
      "Scalfaro\n",
      "Scalfaro\n",
      "Scalfaro\n",
      "Marlow\n",
      "Marlow\n",
      "Major\n",
      "Leszic\n",
      "Crofts\n",
      "Nat\n",
      "Lab\n",
      "Shimpei\n",
      "PT\n",
      "Siti\n",
      "Supple\n",
      "Supple\n",
      "Supple\n",
      "Hisao\n",
      "Gladishiva\n",
      "Heidi\n",
      "Beth\n",
      "Goetschl\n",
      "Heidi\n",
      "Miriam\n",
      "Heidi\n",
      "Deborah\n",
      "Miriam\n",
      "Svetland\n",
      "Heidi\n",
      "Miriam\n",
      "Miriam\n",
      "Heidi\n",
      "Brigitte\n",
      "Grete\n",
      "Patrizia\n",
      "Behle\n",
      "Greiner-Petter-Memm\n",
      "Shimer\n",
      "Cuo\n",
      "Xu\n",
      "Alexis\n",
      "Blanc\n",
      "Foucras\n",
      "Sepp\n",
      "Reto\n",
      "Jakobs\n",
      "Erwin\n",
      "Georg\n",
      "Alexis\n",
      "Dmitri\n",
      "Jacqui\n",
      "Xu\n",
      "Takanobu\n",
      "Ari-Pekka\n",
      "Brenden\n",
      "Saitoh\n",
      "Espen\n",
      "Primoz\n",
      "Ye\n",
      "Shimizu\n",
      "Yamakage\n",
      "Inoue\n",
      "Jin\n",
      "Inoue\n",
      "Becky\n",
      "Xue\n",
      "Laudrup\n",
      "Sturridge\n",
      "Branch\n",
      "Townsend\n",
      "Holdsworth\n",
      "Darryl\n",
      "Rob\n",
      "Trevor\n",
      "Merwe\n",
      "Astrit\n",
      "Hafizi\n",
      "Hafizi\n",
      "Blendi\n",
      "Nevil\n",
      "Harper\n",
      "Ko\n",
      "Suwandi\n",
      "Yeyen\n",
      "Roh\n",
      "Ko\n",
      "Yoo\n",
      "Bakhit\n",
      "Jassem\n",
      "Koo\n",
      "Jeon\n",
      "RIBALTA\n",
      "Axel\n",
      "Davor\n",
      "Davor\n",
      "Zeljko\n",
      "Vampeta\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and tag distribution function\n",
    "def tokenize_and_distribute_tags(examples):\n",
    "\ttokenized_inputs = tokenizer(\n",
    "\t\texamples[\"tokens\"],\n",
    "\t\ttruncation=True,\n",
    "\t\tis_split_into_words=True,\n",
    "\t\tpadding='max_length',\n",
    "\t\tmax_length=128\n",
    "\t)\n",
    "\n",
    "\tlabels = []\n",
    "\tfor i, label in enumerate(examples[\"ner_tags\"]):\n",
    "\t\tword_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "\n",
    "\t\t# For loop written by Claude 3.5 Sonnet\n",
    "\t\t# It iterates through all the example tokens and classifies it as female or male\n",
    "\t\tmodified_labels = []\n",
    "\t\tfor j, tag in enumerate(label):\n",
    "\t\t\tif (tag == 1 or tag == 2) and isShortNonsense(examples[\"tokens\"][i][j]):\t# Implemented by myself, Drew Lickman\n",
    "\t\t\t\tmodified_labels.append(tag)\n",
    "\t\t\telif tag == 1:\t# If it's a B-PERSON tag\n",
    "\t\t\t\t# Check the actual token using examples[\"tokens\"][i][j]\n",
    "\t\t\t\tif is_female_name(examples[\"tokens\"][i][j]):\t# Implemented by myself, Drew Lickman\n",
    "\t\t\t\t\tmodified_labels.append(9)\t# Convert B-PERSON to B-FPER index\n",
    "\t\t\t\telif is_male_name(examples[\"tokens\"][i][j]):\n",
    "\t\t\t\t\tmodified_labels.append(1)\t# Convert B-PERSON to B-MPER index\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(examples[\"tokens\"][i][j])\n",
    "\t\t\t\t\tmodified_labels.append(tag)\n",
    "\t\t\telif tag == 2:\t# If it's an I-PERSON tag\t# Note: this might miss names split into more than 2 tokens\n",
    "\t\t\t\t# Keep the same type (MPER or FPER) as the previous B- tag\n",
    "\t\t\t\tif modified_labels[-1] == 9:\t# If previous was B-FPER\n",
    "\t\t\t\t\tmodified_labels.append(10)\t# I-FPER index\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tmodified_labels.append(2)\t# I-MPER index\n",
    "\t\t\telse:\t# Not a person tag\n",
    "\t\t\t\tmodified_labels.append(tag)\n",
    "\n",
    "\t\tlabel_ids = [-100 if word_id is None else modified_labels[word_id] for word_id in word_ids]\n",
    "\t\t#label_ids = [-100 if word_id is None else label[word_id] for word_id in word_ids]\n",
    "\t\t#print(f\"Tag List: {label_list}\\n\\nTokens: {examples['tokens'][0]}\\n\\nTokenized: {tokenized_inputs.tokens(batch_index=i)} \\\n",
    "\t\t#\\n\\nTags: {label}\\n\\nTokenized word ids: {word_ids}\\n\\nDistributed tags: {label_ids}\")\n",
    "\t\t#input()\n",
    "\t\tlabels.append(label_ids)\n",
    "\n",
    "\ttokenized_inputs[\"labels\"] = labels\n",
    "\treturn tokenized_inputs\n",
    "\n",
    "# Apply the tokenization function to the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_and_distribute_tags, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aa3111c-00ed-4f91-a0dd-87859c4fe4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric fucntion\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = \\\n",
    "        [ [label_list[label] for label in label_seq if label != -100] for label_seq in labels ]\n",
    "    model_predictions = \\\n",
    "        [ [label_list[pred] for (pred, label) in zip(pred_seq, label_seq) if label != -100] for pred_seq, label_seq in zip(predictions, labels) ]\n",
    "\n",
    "    results = metric.compute(predictions=model_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62951229-e1b6-4094-8c5d-b60e0f4620c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Set training arguments\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Instantiate trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e9373f6-87c5-4c94-b2c1-a37e0a604a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220/220 04:23, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.178627</td>\n",
       "      <td>0.743375</td>\n",
       "      <td>0.780190</td>\n",
       "      <td>0.761338</td>\n",
       "      <td>0.943543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-220 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.17862732708454132, 'eval_precision': 0.7433749358864763, 'eval_recall': 0.7801902027633232, 'eval_f1': 0.7613377692172999, 'eval_accuracy': 0.9435426854415837, 'eval_runtime': 21.9733, 'eval_samples_per_second': 147.906, 'eval_steps_per_second': 2.321, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97522582-7de3-4fd4-adbc-8084d21595c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "pred_labels = np.argmax(predictions.predictions, axis=2)\n",
    "true_labels = predictions.label_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
