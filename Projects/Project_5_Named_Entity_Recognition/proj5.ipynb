{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94a727b",
   "metadata": {},
   "source": [
    "Drew Lickman\n",
    "\n",
    "CSCI 4820-1\n",
    "\n",
    "Project #5\n",
    "\n",
    "Due: 11/19/24\n",
    "\n",
    "A.I. Disclaimer: Work for this assignment was completed with the aid of artificial intelligence tools and comprehensive documentation of the names of, input provided to, and output obtained from, these tools is included as part of my assignment submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdef41-3485-495c-9361-172cd74aeabb",
   "metadata": {},
   "source": [
    "# BERT Named Entity Recognition Fine Tuning Project Starter Code\n",
    "### Dr. Sal Barbosa, Department of Computer Science, Middle Tennessee State University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b23c7ff9-6894-4417-98e3-f743546e6d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required on TAMU FASTER to be able to pip install packages and download the dataset from Hugging Face\n",
    "import os\n",
    "os.environ['http_proxy'] = 'http://10.72.8.25:8080'\n",
    "os.environ['https_proxy'] = 'http://10.72.8.25:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30529efd-2c95-45db-98e5-1d9d87c95c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip installs - comment out after running the notebook for the first time\n",
    "#!pip install datasets\n",
    "#!pip install evaluate\n",
    "#!pip install seqeval\n",
    "#!pip install accelerate==0.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f508615-b7a1-4962-ad3c-298ede099e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, DatasetDict, Sequence, ClassLabel\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9030258-084f-44ff-ae21-0321302ffeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CONLL-2003 NER dataset\n",
    "dataset = load_dataset(\"conll2003\")\n",
    "\n",
    "# Remove columns not used in this code\n",
    "dataset = dataset.remove_columns(['id', 'pos_tags', 'chunk_tags'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041a113-2e7d-4691-be22-30b79bef7078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and display the NER tag list for the dataset\n",
    "label_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "# Rename PERSON labels to MALE labels\n",
    "label_list[1] = 'B-MPER'\n",
    "label_list[2] = 'I-MPER'\n",
    "\n",
    "# Append FEMALE labels at end of label list\n",
    "label_list.append('B-FPER')\n",
    "label_list.append('I-FPER')\n",
    "\n",
    "print(\"Label list:\", label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40342865-4e3e-4616-8b76-8a5f212e05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT cased model\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a4990",
   "metadata": {},
   "source": [
    "## I used Claude 3.5 Sonnet (New) to create a basic classifier to help in labeling the name prefix/suffix patterns, instead of labeling entire individual names. Not all of Claude's predictions were true, so I spent a few hours manually labeling the prefixes and suffixes as male or female (in the next code block). Claude was able to give me a rough probability estimate of the name's gender, but I specifically chose the actual prefixes and suffixes to be used. I also had Claude create a table of the 5 highest potential suffixes and prefixes, which was slightly helpful, but not as helpful as I was hoping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb7eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import React, { useState, useEffect } from 'react';\n",
    "# import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';\n",
    "# import _ from 'lodash';\n",
    "\n",
    "# const NameGenderProcessor = () => {\n",
    "# const [input, setInput] = useState('');\n",
    "# const [output, setOutput] = useState('');\n",
    "# const [patternAnalysis, setPatternAnalysis] = useState('');\n",
    "\n",
    "# const predictGender = (name) => {\n",
    "# \tname = name.toLowerCase().trim();\n",
    "# \tlet femaleScore = 0;\n",
    "# \tlet maleScore = 0;\n",
    "\t\n",
    "# \t// Strong male name patterns (endings)\n",
    "# \tconst strongMaleEndings = [\n",
    "# \t{ pattern: 'bert', weight: 0.85 }, // Robert, Albert\n",
    "# \t{ pattern: 'son', weight: 0.85 },  // Wilson, Jackson\n",
    "# \t{ pattern: 'ard', weight: 0.8 },   // Richard, Edward\n",
    "# \t{ pattern: 'rick', weight: 0.8 },  // Patrick, Frederick\n",
    "# \t{ pattern: 'les', weight: 0.75 },  // Charles, Miles\n",
    "# \t{ pattern: 'roy', weight: 0.75 },  // Troy, Leroy\n",
    "# \t{ pattern: 'ryan', weight: 0.75 }, // Bryan, Ryan\n",
    "# \t{ pattern: 'ton', weight: 0.7 },   // Clinton, Winston\n",
    "# \t{ pattern: 'ford', weight: 0.7 },  // Bradford, Clifford\n",
    "# \t{ pattern: 'vin', weight: 0.65 }   // Kevin, Calvin\n",
    "# \t];\n",
    "\n",
    "# \t// Strong female name patterns (endings)\n",
    "# \tconst strongFemaleEndings = [\n",
    "# \t{ pattern: 'ette', weight: 0.9 },  // Annette, Paulette\n",
    "# \t{ pattern: 'elle', weight: 0.9 },  // Michelle, Belle\n",
    "# \t{ pattern: 'ina', weight: 0.85 },  // Christina, Marina\n",
    "# \t{ pattern: 'yah', weight: 0.85 },  // Mariah, Aliyah\n",
    "# \t{ pattern: 'iah', weight: 0.85 },  // Moriah, Sariah\n",
    "# \t{ pattern: 'lyn', weight: 0.85 },  // Evelyn, Carolyn\n",
    "# \t{ pattern: 'anne', weight: 0.8 },  // Suzanne, Marianne\n",
    "# \t{ pattern: 'ella', weight: 0.85 }, // Isabella, Stella\n",
    "# \t{ pattern: 'icia', weight: 0.85 }, // Patricia, Alicia\n",
    "# \t{ pattern: 'ley', weight: 0.8 },   // Ashley, Shirley\n",
    "# \t{ pattern: 'acy', weight: 0.8 },   // Tracy, Stacy\n",
    "# \t{ pattern: 'ren', weight: 0.75 },  // Lauren, Karen\n",
    "# \t{ pattern: 'rie', weight: 0.75 },  // Marie, Carrie\n",
    "# \t{ pattern: 'ora', weight: 0.75 },  // Flora, Nora\n",
    "# \t{ pattern: 'ey', weight: 0.7 }     // Sydney, Casey\n",
    "# \t];\n",
    "\n",
    "# \t// Male name beginnings\n",
    "# \tconst maleBeginnings = [\n",
    "# \t{ pattern: 'jo', weight: 0.65 },   // John, Joseph\n",
    "# \t{ pattern: 'br', weight: 0.6 },    // Bruce, Brandon\n",
    "# \t{ pattern: 'gr', weight: 0.6 },    // Greg, Grant\n",
    "# \t{ pattern: 'fr', weight: 0.6 },    // Frank, Frederick\n",
    "# \t{ pattern: 'st', weight: 0.5 }     // Steve, Stanley\n",
    "# \t];\n",
    "\n",
    "# \t// Female name beginnings\n",
    "# \tconst femaleBeginnings = [\n",
    "# \t{ pattern: 'mel', weight: 0.6 },   // Melissa, Melody\n",
    "# \t{ pattern: 'syl', weight: 0.6 },   // Sylvia\n",
    "# \t{ pattern: 'bel', weight: 0.6 },   // Belinda, Isabella\n",
    "# \t{ pattern: 'flo', weight: 0.6 },   // Florence\n",
    "# \t{ pattern: 'mar', weight: 0.6 },   // Mary, Maria\n",
    "# \t{ pattern: 'ali', weight: 0.6 }    // Alice, Alicia\n",
    "# \t];\n",
    "\n",
    "# \t// Check strong patterns first\n",
    "# \tstrongMaleEndings.forEach(({ pattern, weight }) => {\n",
    "# \tif (name.endsWith(pattern)) maleScore += weight;\n",
    "# \t});\n",
    "\n",
    "# \tstrongFemaleEndings.forEach(({ pattern, weight }) => {\n",
    "# \tif (name.endsWith(pattern)) femaleScore += weight;\n",
    "# \t});\n",
    "\n",
    "# \t// Check beginnings\n",
    "# \tmaleBeginnings.forEach(({ pattern, weight }) => {\n",
    "# \tif (name.startsWith(pattern)) maleScore += weight;\n",
    "# \t});\n",
    "\n",
    "# \tfemaleBeginnings.forEach(({ pattern, weight }) => {\n",
    "# \tif (name.startsWith(pattern)) femaleScore += weight;\n",
    "# \t});\n",
    "\n",
    "# \t// Consonant patterns (more common in male names)\n",
    "# \tconst hasStrongConsonantCluster = /[bcdfghjklmnpqrstvwxz]{3,}/.test(name);\n",
    "# \tif (hasStrongConsonantCluster) maleScore += 0.3;\n",
    "\n",
    "# \t// Soft sound patterns (more common in female names)\n",
    "# \tconst hasSoftEnding = /[aeiou][ah]$|[aeiou]e$/.test(name);\n",
    "# \tif (hasSoftEnding) femaleScore += 0.5;\n",
    "\n",
    "# \t// Final letter patterns\n",
    "# \tconst finalLetter = name.slice(-1);\n",
    "# \tif ('aie'.includes(finalLetter)) femaleScore += 0.4;\n",
    "# \tif ('ntkds'.includes(finalLetter)) maleScore += 0.3;\n",
    "\n",
    "# \t// Vowel patterns\n",
    "# \tconst vowelCount = (name.match(/[aeiou]/g) || []).length;\n",
    "# \tconst nameLength = name.length;\n",
    "# \tconst vowelRatio = vowelCount / nameLength;\n",
    "\n",
    "# \tif (vowelRatio > 0.45) femaleScore += 0.4;\n",
    "# \tif (vowelRatio < 0.25) maleScore += 0.3;\n",
    "\n",
    "# \t// Repeated letter patterns (more common in female names)\n",
    "# \tconst hasRepeatedLetters = /(.)\\1/.test(name);\n",
    "# \tif (hasRepeatedLetters) femaleScore += 0.3;\n",
    "\n",
    "# \t// Additional female patterns\n",
    "# \tconst hasMultipleVowelClusters = (name.match(/[aeiou]{2,}/g) || []).length;\n",
    "# \tif (hasMultipleVowelClusters > 0) femaleScore += 0.3;\n",
    "\n",
    "# \t// Ensure minimum scores\n",
    "# \tmaleScore = Math.max(maleScore, 0.2);\n",
    "# \tfemaleScore = Math.max(femaleScore, 0.2);\n",
    "\n",
    "# \t// Calculate confidence percentage\n",
    "# \tconst total = femaleScore + maleScore;\n",
    "# \tconst maxScore = Math.max(femaleScore, maleScore);\n",
    "# \tconst confidence = Math.min(Math.round((maxScore / total) * 100), 95); // Cap at 95%\n",
    "\n",
    "# \treturn {\n",
    "# \tgender: femaleScore > maleScore ? 'Female' : 'Male',\n",
    "# \tconfidence\n",
    "# \t};\n",
    "# };\n",
    "\n",
    "# const analyzePatterns = (names) => {\n",
    "# \tif (!names.trim()) {\n",
    "# \tsetPatternAnalysis('No data to analyze yet. Enter some names above.');\n",
    "# \treturn;\n",
    "# \t}\n",
    "\n",
    "# \tconst namesList = names.split('\\n').filter(name => name.trim());\n",
    "# \tconst patterns = {\n",
    "# \tmaleStartings: { '1': {}, '2': {}, '3': {}, '4': {}, '5': {} },\n",
    "# \tmaleEndings: { '1': {}, '2': {}, '3': {}, '4': {}, '5': {} },\n",
    "# \tfemaleStartings: { '1': {}, '2': {}, '3': {}, '4': {}, '5': {} },\n",
    "# \tfemaleEndings: { '1': {}, '2': {}, '3': {}, '4': {}, '5': {} }\n",
    "# \t};\n",
    "\n",
    "# \t// Process each name\n",
    "# \tnamesList.forEach(nameInput => {\n",
    "# \tconst name = nameInput.trim().toLowerCase();\n",
    "# \tif (!name) return;\n",
    "\n",
    "# \tconst result = predictGender(name);\n",
    "# \tconst confidence = result.confidence / 100;\n",
    "\n",
    "# \t// Only consider patterns from predictions with confidence > 60%\n",
    "# \tif (confidence < 0.6) return;\n",
    "\n",
    "# \t// Get patterns of lengths 1-5 for both start and end\n",
    "# \tfor (let i = 1; i <= 5; i++) {\n",
    "# \t\tif (name.length >= i) {\n",
    "# \t\tconst start = name.slice(0, i);\n",
    "# \t\tconst end = name.slice(-i);\n",
    "\t\t\n",
    "# \t\tif (result.gender === 'Male') {\n",
    "# \t\t\tpatterns.maleStartings[i][start] = (patterns.maleStartings[i][start] || 0) + confidence;\n",
    "# \t\t\tpatterns.maleEndings[i][end] = (patterns.maleEndings[i][end] || 0) + confidence;\n",
    "# \t\t} else {\n",
    "# \t\t\tpatterns.femaleStartings[i][start] = (patterns.femaleStartings[i][start] || 0) + confidence;\n",
    "# \t\t\tpatterns.femaleEndings[i][end] = (patterns.femaleEndings[i][end] || 0) + confidence;\n",
    "# \t\t}\n",
    "# \t\t}\n",
    "# \t}\n",
    "# \t});\n",
    "\n",
    "# \t// Helper function to get top patterns\n",
    "# \tconst getTopPatterns = (patternObj, count = 5) => {\n",
    "# \treturn Object.entries(patternObj)\n",
    "# \t\t.sort((a, b) => b[1] - a[1])\n",
    "# \t\t.slice(0, count)\n",
    "# \t\t.map(([pattern, score]) => `${pattern} (${(score/namesList.length * 100).toFixed(1)}%)`)\n",
    "# \t\t.join('\\n    ');\n",
    "# \t};\n",
    "\n",
    "# \t// Format analysis for each length and type\n",
    "# \t// Helper function to format top 5 patterns for a cell\n",
    "# \tconst formatCell = (patterns) => {\n",
    "# \tif (!patterns || patterns.length === 0) return '-';\n",
    "# \treturn Object.entries(patterns)\n",
    "# \t\t.sort((a, b) => b[1] - a[1])\n",
    "# \t\t.slice(0, 5)\n",
    "# \t\t.map(([pattern, score]) => `${pattern} (${(score/namesList.length * 100).toFixed(1)}%)`)\n",
    "# \t\t.join('\\n\\t');\n",
    "# \t};\n",
    "\n",
    "# \t// Create table header\n",
    "# \tlet table = ['Pattern Analysis (based on ' + namesList.length + ' names)\\n\\n'];\n",
    "# \ttable.push('Length\\tMale Start\\tMale End\\tFemale Start\\tFemale End\\n');\n",
    "# \ttable.push('-'.repeat(105) + '\\n');\n",
    "\n",
    "# \t// Generate each row of the table for lengths 1-5\n",
    "# \tfor (let length = 1; length <= 5; length++) {\n",
    "# \t// Get top 5 patterns for each category\n",
    "# \tconst maleStarts = formatCell(patterns.maleStartings[length.toString()]);\n",
    "# \tconst maleEnds = formatCell(patterns.maleEndings[length.toString()]);\n",
    "# \tconst femaleStarts = formatCell(patterns.femaleStartings[length.toString()]);\n",
    "# \tconst femaleEnds = formatCell(patterns.femaleEndings[length.toString()]);\n",
    "\n",
    "# \t// Split each category into lines (they'll have 5 lines each)\n",
    "# \tconst maleStartLines = maleStarts.split('\\n');\n",
    "# \tconst maleEndLines = maleEnds.split('\\n');\n",
    "# \tconst femaleStartLines = femaleStarts.split('\\n');\n",
    "# \tconst femaleEndLines = femaleEnds.split('\\n');\n",
    "\n",
    "# \t// Add the length indicator and first line\n",
    "# \ttable.push(`${length}\\t${maleStartLines[0]}\\t${maleEndLines[0]}\\t${femaleStartLines[0]}\\t${femaleEndLines[0]}\\n`);\n",
    "\t\n",
    "# \t// Add remaining lines with proper spacing\n",
    "# \tfor (let i = 1; i < 5; i++) {\n",
    "# \t\ttable.push(`\\t${maleStartLines[i] || ''}\\t${maleEndLines[i] || ''}\\t${femaleStartLines[i] || ''}\\t${femaleEndLines[i] || ''}\\n`);\n",
    "# \t}\n",
    "\t\n",
    "# \t// Add separator between lengths\n",
    "# \ttable.push('-'.repeat(105) + '\\n');\n",
    "# \t}\n",
    "\n",
    "# \ttable.push('\\nNote: Percentages indicate frequency weighted by confidence scores.');\n",
    "\n",
    "# \tsetPatternAnalysis(table.join(''));\n",
    "\n",
    "# \tsetPatternAnalysis(table.join(''));\n",
    "\n",
    "# \tsetPatternAnalysis(table.join(''));\n",
    "\n",
    "# \tsetPatternAnalysis(analysisText);\n",
    "# };\n",
    "\n",
    "# const processNames = (text) => {\n",
    "# \tconst lines = text.split('\\n');\n",
    "# \tconst results = {\n",
    "# \tmale: [],\n",
    "# \tfemale: []\n",
    "# \t};\n",
    "\n",
    "# \t// Process and categorize each name\n",
    "# \tlines.forEach(line => {\n",
    "# \tconst trimmedLine = line.trim();\n",
    "# \tif (!trimmedLine) return;\n",
    "\t\n",
    "# \tconst result = predictGender(trimmedLine);\n",
    "# \tconst entry = {\n",
    "# \t\tname: trimmedLine,\n",
    "# \t\tconfidence: result.confidence,\n",
    "# \t\tformatted: `${trimmedLine}: ${result.gender} (${result.confidence}% confidence)`\n",
    "# \t};\n",
    "\t\n",
    "# \tif (result.gender === 'Male') {\n",
    "# \t\tresults.male.push(entry);\n",
    "# \t} else {\n",
    "# \t\tresults.female.push(entry);\n",
    "# \t}\n",
    "# \t});\n",
    "\n",
    "# \t// Sort each category by confidence (descending)\n",
    "# \tresults.male.sort((a, b) => b.confidence - a.confidence);\n",
    "# \tresults.female.sort((a, b) => b.confidence - a.confidence);\n",
    "\n",
    "# \t// Format the output with headers and sorted results\n",
    "# \tconst outputText = [\n",
    "# \t`FEMALE NAMES (${results.female.length} total):`,\n",
    "# \t...results.female.map(entry => entry.formatted),\n",
    "# \t'',\n",
    "# \t`MALE NAMES (${results.male.length} total):`,\n",
    "# \t...results.male.map(entry => entry.formatted)\n",
    "# \t].join('\\n');\n",
    "\n",
    "# \tsetOutput(outputText);\n",
    "\t\n",
    "# \t// Analyze patterns whenever names are processed\n",
    "# \tanalyzePatterns(text);\n",
    "# };\n",
    "\n",
    "# const handleInputChange = (e) => {\n",
    "# \tconst newInput = e.target.value;\n",
    "# \tsetInput(newInput);\n",
    "# \tprocessNames(newInput);\n",
    "# };\n",
    "\n",
    "# return (\n",
    "# \t<Card className=\"w-full max-w-4xl\">\n",
    "# \t<CardHeader>\n",
    "# \t\t<CardTitle>Enhanced Name Gender Processor</CardTitle>\n",
    "# \t</CardHeader>\n",
    "# \t<CardContent className=\"space-y-4\">\n",
    "# \t\t<div>\n",
    "# \t\t<label className=\"block text-sm font-medium mb-2\">\n",
    "# \t\t\tInput Names (one per line)\n",
    "# \t\t</label>\n",
    "# \t\t<textarea\n",
    "# \t\t\tvalue={input}\n",
    "# \t\t\tonChange={handleInputChange}\n",
    "# \t\t\tclassName=\"w-full h-48 p-2 border rounded-md\"\n",
    "# \t\t\tplaceholder=\"Enter names here...\"\n",
    "# \t\t/>\n",
    "# \t\t</div>\n",
    "# \t\t<div>\n",
    "# \t\t<label className=\"block text-sm font-medium mb-2\">\n",
    "# \t\t\tProcessed Results (with confidence scores)\n",
    "# \t\t</label>\n",
    "# \t\t<textarea\n",
    "# \t\t\tvalue={output}\n",
    "# \t\t\treadOnly\n",
    "# \t\t\tclassName=\"w-full h-48 p-2 border rounded-md bg-gray-50\"\n",
    "# \t\t/>\n",
    "# \t\t</div>\n",
    "# \t\t<div>\n",
    "# \t\t<label className=\"block text-sm font-medium mb-2\">\n",
    "# \t\t\tPattern Analysis\n",
    "# \t\t</label>\n",
    "# \t\t<textarea\n",
    "# \t\t\tvalue={patternAnalysis}\n",
    "# \t\t\treadOnly\n",
    "# \t\t\tclassName=\"w-full h-48 p-2 border rounded-md bg-gray-50 font-mono text-sm\"\n",
    "# \t\t/>\n",
    "# \t\t</div>\n",
    "# \t</CardContent>\n",
    "# \t</Card>\n",
    "# );\n",
    "# };\n",
    "\n",
    "# export default NameGenderProcessor;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89b56bf5-d3e0-41eb-adc2-bab03c12e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isShortNonsense(token):\n",
    "    # Removes any tokens that include non alphabetic characters, or single chars\n",
    "    if not token.isalpha() or len(token) == 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Some names came from https://nameberry.com/blog/the-most-popular-baby-name-endings 11/15/24\n",
    "femaleWhole = (\"Taha\", \"Olga\", \"Andi\", \"Inga\", \"Ro\", \"Deby\", \"Abu\", \"Mia\", \"Rui\", \"Tracy\", \"El\", \"Kim\", \"Lauren\", \"Ai\", \"Ebe\", \"Ruth\", \"Andrea\", \"An\")\n",
    "femaleBeginnings = (\"ali\", \"hart\", \"sene\", \"xu\", \"cuo\", \"esp\", \"blen\", \"nas\", \"arc\", \"jass\", \"anin\", \"oue\", \"pan\", \"vale\", \"pam\", \"sno\", \"swua\", \"hab\", \"laud\", \"van\", \"giu\", \"coe\", \"zer\", \"sih\", \"anne\", \"nsa\", \"jaa\", \"masa\", \"kha\", \"angh\", \"wata\", \"oej\", \"ther\", \"qia\", \"mai\", \"erd\", \"dai\", \"vio\", \"hafi\", \"pauli\", \"claudi\", \"cuau\", \"lian\", \"lel\", \"nye\", \"coz\", \"igo\", \"oce\", \"jai\", \"hai\", \"hei\", \"pata\", \"gou\", \"jupp\", \"mus\", \"ove\", \"agui\", \"iva\", \"wits\", \"kusu\", \"marie\", \"est\", \"tuli\", \"soe\", \"mary\", \"las\", \"piz\", \"kord\", \"asan\", \"flo\", \"xia\", \"ovi\", \"mont\", \"yal\", \"gen\", \"tan\", \"harb\", \"pica\", \"kat\", \"bh\", \"wie\", \"gwe\", \"heal\", \"hild\", \"alic\", \"ott\", \"eki\", \"hos\", \"pud\", \"sara\", \"male\", \"nai\", \"jee\", \"lea\", \"ciri\", \"paol\", \"mere\", \"lind\", \"bai\", \"chi\", \"olivi\", \"cha\", \"eyl\", \"zun\", \"lore\", \"tara\", \"ise\", \"woo\", \"pet\", \"gius\", \"cook\", \"fab\", \"ghe\", \"syb\", \"juh\", \"bell\", \"charli\", \"asi\", \"lie\", \"chiq\", \"duf\", \"yas\", \"zit\", \"may\", \"kimi\", \"joha\", \"ili\", \"luo\", \"viv\", \"hill\", \"min\", \"marg\", \"till\")\n",
    "femaleEndings = (\"ati\", \"xis\", \"lde\", \"yte\", \"gla\", \"rwe\", \"hla\", \"ta\", \"tto\", \"tle\", \"ye\", \"ivo\", \"evre\", \"odi\", \"eto\", \"pei\", \"mian\", \"head\", \"ziat\", \"kka\", \"bri\", \"mor\", \"rka\", \"yap\", \"pul\", \"puls\", \"sca\", \"lau\", \"uzu\", \"xmi\", \"sheu\", \"dka\", \"nina\", \"inat\", \"eix\", \"kio\", \"ote\", \"ete\", \"ono\", \"olo\", \"nil\", \"ery\", \"wa\", \"oka\", \"sy\", \"hle\", \"hah\", \"mra\", \"mao\", \"kme\", \"ril\", \"kage\", \"irou\", \"ayr\", \"ucy\", \"icol\", \"ddy\", \"afa\", \"ti\", \"upu\", \"zka\", \"ardi\", \"umi\", \"mma\", \"toa\", \"ota\", \"tty\", \"iss\", \"zer\" \"feru\", \"rix\", \"erdy\", \"iris\", \"ois\", \"esa\", \"ohl\", \"ega\", \"eja\", \"bah\", \"ldi\", \"qui\", \"lta\", \"imo\", \"ook\", \"oke\", \"iec\", \"dou\", \"tae\", \"iji\", \"endy\", \"kyo\", \"hiko\", \"aru\", \"iz\", \"tas\", \"ofi\", \"ste\", \"awn\", \"etz\", \"alu\", \"ese\", \"izi\", \"uma\", \"oo\", \"eki\", \"amy\", \"eth\", \"rmi\", \"ente\", \"va\", \"chma\", \"uig\", \"oue\", \"see\", \"eem\", \"aka\", \"afi\", \"lio\", \"sao\", \"eta\", \"xue\", \"bose\", \"ulo\", \"org\", \"cio\", \"lao\", \"ubo\", \"ime\", \"toh\", \"idi\", \"eon\", \"ody\", \"zia\", \"zie\", \"ice\", \"utu\", \"jah\", \"rah\", \"yi\", \"roh\", \"reh\", \"meh\", \"yeh\", \"aou\", \"pple\", \"rla\", \"iti\", \"imi\", \"tea\", \"anni\", \"rose\", \"ecky\" \"une\", \"nzu\", \"bel\", \"bell\", \"aoui\", \"tti\", \"kat\", \"sza\", \"ski\", \"cia\", \"de\", \"fer\", \"nose\", \"ess\", \"ya\", \"ith\", \"cis\", \"ska\", \"hge\", \"nga\", \"uska\", \"urin\", \"ero\", \"sey\", \"dia\", \"eri\", \"rle\", \"fje\", \"rey\", \"shi\", \"tia\", \"nne\", \"rie\", \"chua\", \"oke\", \"gan\", \"uu\", \"ala\", \"hai\", \"ura\", \"oki\", \"ude\", \"ehe\", \"ada\", \"nez\", \"uya\", \"nka\", \"ake\", \"lin\", \"isa\", \"jup\", \"guz\", \"ail\", \"uil\", \"ief\", \"ail\", \"lyn\", \"rgy\", \"erin\", \"oan\", \"cin\", \"ncy\", \"ace\", \"ssa\", \"sea\", \"air\", \"kim\", \"oao\", \"hild\", \"ppo\", \"nes\", \"ble\", \"tja\", \"slaw\", \"amm\", \"aly\", \"ely\", \"aish\", \"ooch\", \"sta\", \"nge\", \"ilo\", \"nna\", \"rel\", \"lva\", \"dle\", \"awa\", \"na\", \"ila\", \"piot\", \"fah\", \"ffel\", \"asa\", \"lle\", \"aas\", \"adi\", \"tta\", \"miya\", \"buza\", \"vai\", \"udi\", \"ita\", \"ira\", \"aga\", \"ami\", \"ica\", \"igi\", \"ori\", \"cre\", \"nda\", \"era\", \"icky\", \"iya\", \"yste\", \"li\", \"dea\", \"ha\", \"cu\", \"uc\", \"eah\", \"ure\", \"ate\", \"oche\", \"tel\", \"ele\", \"ee\", \"chi\", \"eva\", \"karo\", \"eggy\", \"via\", \"ama\", \"eles\", \"ope\", \"ela\", \"ona\", \"anda\", \"rii\", \"lly\", \"lli\", \"nja\", \"oku\", \"weyi\", \"sha\", \"aki\", \"pese\", \"alo\", \"tra\", \"elo\", \"rpe\", \"oto\", \"omo\", \"osa\", \"ghe\", \"ini\", \"rei\", \"are\", \"mmi\", \"ena\", \"luca\", \"thia\", \"una\", \"lah\", \"ewa\", \"aba\", \"eira\", \"aan\", \"gle\", \"xei\", \"eve\", \"erre\", \"wicz\", \"issa\", \"lat\", \"ima\", \"uta\", \"ley\", \"xia\", \"oe\", \"que\", \"nia\", \"hia\", \"iza\", \"erly\", \"ean\", \"ylis\", \"iew\", \"wicz\", \"issy\", \"dra\", \"abi\", \"rta\", \"aya\", \"gato\", \"cca\", \"oko\", \"gma\", \"ika\", \"ay\", \"ies\", \"zio\", \"arda\", \"oux\", \"ore\", \"elli\", \"raj\", \"antha\", \"gne\", \"kki\", \"evic\", \"ino\", \"ene\", \"si\", \"az\", \"uki\", \"ise\", \"ova\", \"oin\", \"ria\", \"ata\", \"anne\", \"drea\", \"ayla\", \"essa\", \"her\", \"anna\", \"ana\", \"tte\", \"etta\", \"elle\", \"ella\", \"ina\", \"yah\", \"iah\", \"lyn\", \"icia\", \"rie\", \"ora\", \"lie\", \"thy\", \"atie\", \"rude\", \"lia\", \"lla\", \"enna\", \"ine\", \"ani\", \"ola\", \"een\", \"ahi\", \"kie\", \"ane\", \"ahu\", \"ara\", \"ari\", \"mbe\", \"pta\", \"ady\", \"ie\", \"ary\", \"xa\")\n",
    "def is_female_name(token):\n",
    "    # Uses algorithmic approach to assign gender tag and returns boolean\n",
    "    result = False\n",
    "    #if any(token.lower().endswith(ending) for ending in femaleEndings):\n",
    "    if token.lower().endswith(femaleEndings):\n",
    "        result = True\n",
    "    #elif any(token.lower().startswith(start) for start in femaleBeginnings):\n",
    "    elif token.lower().startswith(femaleBeginnings):\n",
    "        result = True\n",
    "    elif token in femaleWhole:\n",
    "        result = True\n",
    "    #if result: print(\"F:\",token)\n",
    "    return result\n",
    "\n",
    "maleWhole = (\"Jimi\", \"Levy\", \"Sammy\", \"Anders\", \"Ty\", \"Jens\", \"Andre\", \"Cam\", \"Mo\", \"Alec\", \"Gale\", \"Andy\", \"Fred\", \"Nick\", \"Juan\", \"Kenny\", \"Abu\", \"Jay\", \"Tim\", \"Roy\", \"Danny\", \"Liam\", \"Alex\", \"Shen\", \"Costas\", \"Dan\", \"Hal\", \"Sam\", \"Tom\", \"Ken\", \"Daniel\", \"Ian\", \"Blake\")\n",
    "maleBeginnings = (\"man\", \"mr\", \"bat\", \"jyr\", \"japhe\", \"betho\", \"map\", \"gil\", \"lou\", \"rup\", \"arr\", \"beck\", \"jin\", \"blanc\", \"deg\", \"hide\", \"eli\", \"fun\", \"sain\", \"khu\", \"ski\", \"faul\", \"chen\", \"byas\", \"navj\", \"larb\", \"spen\", \"hek\", \"bart\", \"nico\", \"lex\", \"bro\", \"serv\", \"gang\", \"maj\", \"rem\", \"arty\", \"alfo\", \"wals\", \"lom\", \"guil\", \"beli\", \"palm\", \"thab\", \"tend\", \"danu\", \"abel\", \"gais\", \"gca\", \"nag\", \"jami\", \"prim\", \"rib\", \"ben\", \"odno\", \"vas\", \"lud\", \"wim\", \"watt\", \"zah\", \"rust\", \"yeg\", \"kap\", \"lamb\", \"schw\", \"scal\", \"scar\", \"kraf\", \"raph\", \"rome\", \"roma\", \"augu\", \"juliu\", \"roos\", \"crof\", \"tung\", \"joce\", \"run\", \"nort\", \"ralp\", \"jesu\", \"stur\", \"hiro\", \"moto\", \"curt\", \"leon\", \"hog\", \"tre\", \"work\", \"matt\", \"math\", \"taka\", \"law\", \"vit\", \"goet\", \"dmi\", \"hans\", \"kasp\", \"buff\", \"sin\", \"tron\", \"sid\", \"bran\", \"sigu\", \"tow\", \"sti\", \"lars\", \"cair\", \"kurt\", \"str\", \"narc\", \"lyn\", \"rash\", \"zin\", \"von\", \"pire\", \"jerz\", \"erw\", \"win\", \"kafel\", \"rob\", \"chou\", \"warn\", \"tom\", \"roy\", \"henr\", \"san\", \"zel\", \"tavar\", \"gab\", \"bug\", \"wid\", \"uly\", \"dem\", \"jong\", \"lloy\", \"gro\", \"wes\", \"shad\", \"adol\", \"kev\", \"sul\", \"glen\", \"jet\", \"swi\", \"mc\", \"rang\", \"domi\", \"jont\", \"gram\", \"belm\", \"virg\", \"sme\", \"wij\", \"oti\", \"rock\", \"clem\", \"des\", \"sobo\", \"hin\", \"ban\", \"banh\", \"ham\", \"ahm\", \"smy\", \"simo\", \"dro\", \"jar\", \"rai\", \"grz\", \"frit\", \"shkv\", \"fed\", \"orr\", \"korn\", \"sore\", \"nil\", \"die\", \"mur\", \"lan\", \"parn\", \"ant\", \"maur\", \"cy\", \"arn\", \"bour\", \"grae\", \"lew\", \"take\", \"rub\", \"rifk\", \"rugg\", \"hers\", \"hars\", \"agr\", \"arj\", \"max\", \"kar\", \"gran\", \"li\", \"mosh\", \"ed\", \"rip\", \"ren\", \"jan\", \"chris\", \"neal\", \"hu\", \"marc\", \"you\", \"mill\", \"arw\", \"jul\", \"fern\", \"shig\", \"feli\", \"hidem\", \"stew\", \"serg\", \"efa\", \"jose\", \"olin\", \"erik\", \"bry\", \"sato\", \"jone\", \"fred\", \"owen\", \"edb\", \"bena\", \"web\", \"mach\", \"jim\", \"jord\", \"elm\", \"huse\", \"kenn\", \"vog\", \"jeff\", \"buca\", \"Yon\", \"craw\", \"bur\", \"charle\", \"tho\", \"aa\", \"col\", \"kri\", \"javi\", \"moy\", \"hic\", \"gar\", \"hunt\", \"cor\", \"bill\", \"bob\", \"hel\", \"will\", \"mick\", \"con\", \"sal\", \"ric\", \"phi\", \"terr\", \"bru\", \"pete\", \"shay\", \"wern\", \"nikol\", \"fisch\", \"skandal\", \"stef\", \"benj\", \"rabi\", \"must\", \"per\", \"core\", \"dal\", \"gor\", \"pav\", \"coop\", \"ross\", \"car\", \"kaz\", \"bor\", \"asl\", \"bert\", \"cli\", \"stev\", \"pres\", \"berr\", \"greg\")\n",
    "maleEndings = (\"drew\", \"ner\", \"had\", \"das\", \"pt\", \"epp\", \"rki\", \"map\", \"shu\", \"rav\", \"nat\", \"ko\", \"lab\", \"ndi\", \"els\", \"mais\", \"zer\", \"car\", \"yen\", \"phet\", \"zak\", \"uss\", \"nte\", \"hem\", \"dom\", \"mez\", \"nir\", \"bor\", \"inel\", \"ehu\", \"stum\", \"zic\", \"yed\", \"igo\", \"kil\", \"ryo\", \"iji\", \"bir\", \"mpo\", \"rab\", \"amp\", \"qul\", \"orc\", \"osz\", \"met\", \"uan\", \"wett\", \"deo\", \"jat\", \"tik\",\"bby\", \"qr\", \"nby\", \"lucas\", \"ndo\", \"mpo\", \"fet\", \"cep\", \"jid\", \"nso\", \"macho\", \"tov\", \"mul\", \"obs\", \"sto\", \"hit\", \"ouf\", \"jab\", \"rch\", \"rit\", \"dor\", \"esh\", \"pas\", \"uch\", \"yer\", \"esto\", \"onse\", \"avas\", \"war\", \"mr\", \"kar\", \"vais\", \"oys\", \"iro\", \"irat\", \"abo\", \"cras\", \"kash\", \"ugh\", \"jez\", \"euf\", \"zov\", \"eka\", \"zob\", \"ardy\", \"jor\" \"deo\", \"mer\", \"aik\", \"zim\", \"onel\", \"mil\", \"wig\", \"ior\", \"uri\", \"ars\", \"land\", \"oor\", \"eau\", \"sum\", \"sun\", \"dge\", \"cks\", \"abl\", \"clav\", \"aro\", \"eks\", \"olaf\", \"dres\", \"low\", \"ecks\", \"eks\", \"jit\", \"oses\", \"yle\", \"gky\", \"bus\", \"velt\", \"elts\", \"gum\", \"net\", \"nzo\", \"rico\", \"yon\",  \"dem\", \"xon\", \"yce\", \"aer\", \"rdo\", \"eiss\", \"rth\", \"alto\", \"guez\", \"vor\", \"lian\", \"emu\", \"cob\", \"rby\", \"ont\", \"iud\", \"cel\", \"tis\", \"mot\", \"tes\", \"obu\", \"ato\", \"sar\", \"pean\", \"izu\", \"oly\", \"sim\", \"mots\", \"xel\", \"evil\", \"bbs\", \"ish\", \"rin\", \"min\", \"anch\", \"ryl\", \"lez\", \"per\", \"vel\", \"ort\", \"ban\", \"dji\", \"von\", \"span\", \"hak\", \"eak\", \"ews\", \"rid\", \"riam\", \"rian\", \"hid\", \"don\", \"ost\", \"kan\", \"aid\", \"ula\", \"win\", \"ent\", \"den\", \"ciso\", \"enc\", \"aint\", \"elt\", \"hed\", \"bin\", \"ied\", \"gno\", \"sar\", \"est\", \"ust\", \"hon\", \"jko\", \"vio\", \"sch\", \"hul\", \"dov\", \"mme\", \"ret\", \"len\", \"ges\", \"colm\", \"rris\", \"hin\", \"itis\", \"ens\", \"emy\", \"nco\", \"alf\", \"kov\", \"taro\", \"ngo\", \"sma\", \"sby\", \"hrs\", \"rko\", \"cot\", \"irk\", \"els\" \"age\", \"abe\", \"non\", \"art\", \"hty\", \"led\", \"pat\", \"dlen\", \"unt\", \"tan\", \"blo\", \"him\", \"ahl\", \"dev\", \"dis\", \"pol\", \"uet\", \"lor\", \"ksy\", \"kian\", \"nty\", \"cins\", \"jan\", \"trv\", \"rdt\", \"ulz\", \"zon\", \"onk\", \"can\", \"erg\", \"ome\", \"rik\", \"tof\", \"agg\", \"rke\", \"ist\", \"sus\", \"ved\", \"rag\", \"ke\", \"ram\", \"mens\", \"man\", \"men\", \"eck\", \"rry\", \"ryn\", \"kol\", \"dar\", \"del\", \"yev\", \"nsu\", \"kh\", \"nic\", \"rel\", \"ifo\", \"kow\", \"uin\", \"ers\", \"nah\", \"har\", \"gram\", \"khar\", \"hd\", \"dam\", \"dams\", \"erd\", \"gis\", \"acky\", \"ser\", \"yss\", \"rts\", \"nds\", \"med\", \"tz\", \"orz\", \"ndes\", \"uke\", \"ato\", \"yrin\", \"alk\", \"uus\", \"nck\", \"own\", \"klin\", \"dys\", \"rer\", \"hev\", \"ker\", \"esse\", \"oen\", \"ego\", \"iano\", \"ney\", \"wey\", \"geny\", \"lis\", \"nio\", \"icio\", \"lch\", \"raf\", \"yuk\", \"hen\", \"aud\", \"mura\", \"nan\", \"nny\", \"kob\", \"link\", \"rett\", \"andy\", \"aus\", \"cois\", \"kis\", \"ink\", \"ur\", \"ind\", \"ath\", \"ndt\", \"sco\", \"ler\", \"ewt\", \"iser\", \"ein\", \"wis\", \"ind\", \"ien\", \"vik\", \"att\", \"orm\", \"nis\", \"reas\", \"zen\", \"las\", \"cak\", \"sty\", \"ats\", \"vin\", \"lip\", \"nko\", \"ons\", \"ume\", \"tien\", \"iri\", \"ij\", \"ant\", \"cisco\", \"rst\", \"ken\", \"tian\", \"nas\", \"slav\", \"wel\", \"ando\", \"han\", \"lix\", \"wart\", \"gen\", \"rif\", \"emp\", \"ruw\", \"ryan\", \"one\", \"yan\", \"wire\", \"pot\", \"lan\", \"olf\", \"gel\", \"ber\", \"dim\", \"tar\", \"red\", \"borg\", \"scar\", \"naj\", \"eir\", \"iki\", \"man\", \"ven\", \"un\", \"rek\", \"ric\", \"kus\", \"ten\", \"ito\", \"ite\", \"tro\", \"erve\", \"ido\", \"nna\", \"ster\", \"aac\", \"old\", \"ean\", \"eil\", \"rren\", \"gts\", \"orn\", \"roy\", \"les\", \"rio\", \"ter\", \"ral\", \"mond\", \"sen\", \"wan\", \"ado\", \"rak\", \"nn\", \"hew\", \"ier\", \"ike\", \"rgi\", \"vanni\", \"bed\", \"sin\", \"ald\", \"ole\", \"eus\", \"req\", \"chez\", \"nen\", \"ich\", \"pov\", \"nov\", \"dre\", \"mir\", \"erry\", \"ght\", \"lock\", \"utch\", \"os\", \"chel\", \"oel\", \"ert\", \"arl\", \"ger\", \"ald\", \"eld\", \"ford\", \"ques\", \"ott\", \"ham\", \"vic\", \"oft\", \"ump\", \"ance\", \"ius\", \"tor\", \"orge\", \"uis\", \"monn\", \"mir\", \"uzo\", \"oug\", \"ock\", \"ado\", \"dro\", \"tor\", \"nce\", \"cer\", \"hris\", \"iel\", \"ave\", \"ek\", \"mann\", \"tr\", \"din\", \"dan\", \"ung\", \"al\", \"aul\", \"mir\", \"nry\", \"rty\", \"ldo\", \"ack\", \"ver\", \"gos\", \"olas\", \"cott\", \"ard\", \"rco\", \"dict\", \"udan\", \"mut\", \"rnd\", \"vis\", \"ael\", \"yne\", \"ng\", \"ick\", \"oud\", \"ard\", \"onan\", \"kel\", \"ayne\", \"git\", \"eer\", \"son\", \"ank\", \"unk\", \"ion\", \"oey\", \"mes\", \"ll\", \"than\", \"hn\", \"rick\", \"tn\", \"eg\", \"nley\", \"uce\", \"ndon\", \"osh\", \"ony\", \"even\", \"odd\", \"drix\", \"ang\", \"vid\", \"yahu\", \"san\", \"afat\", \"abil\", \"anz\", \"ain\", \"itris\", \"rner\", \"hael\", \"rtin\", \"taq\", \"eed\", \"haq\", \"asim\", \"mad\", \"ncan\", \"aig\", \"nto\", \"vich\", \"od\", \"mon\", \"der\", \"rad\", \"ting\", \"bert\", \"imis\", \"ran\", \"ark\", \"dul\", \"uy\", \"ippe\", \"mas\", \"nus\", \"cil\", \"vey\", \"los\", \"nup\", \"van\", \"uel\", \"ff\", \"rim\", \"pras\", \"dric\", \"uck\", \"ox\", \"vit\", \"jon\", \"ron\", \"ton\", \"dam\", \"rri\", \"sky\", \"fez\", \"mar\", \"sad\", \"tin\", \"usz\", \"qar\", \"rto\", \"ory\")\n",
    "def is_male_name(token):\n",
    "    # Uses algorithmic approach to assign gender tag and returns boolean\n",
    "    result = False\n",
    "    #if any(token.lower().endswith(ending) for ending in maleEndings):\n",
    "    if token.lower().endswith(maleEndings):\n",
    "        result = True\n",
    "    #elif any(token.lower().startswith(start) for start in maleBeginnings):\n",
    "    elif token.lower().startswith(maleBeginnings):\n",
    "        result = True\n",
    "    elif token in maleWhole:\n",
    "        result = True\n",
    "    #if result: print(\"M:\",token)\n",
    "    return result\n",
    "\n",
    "# Implement with more algorithms to specify weights for name parts:\n",
    "# def chooseGender(femResult, maleResult):\n",
    "# \t# If I were to use weights (instead of booleans), I can compare\n",
    "# \tresult = femResult - maleResult\n",
    "# \tif result >= 0:\n",
    "# \t\treturn \"Female\"\n",
    "# \telse:\n",
    "# \t\treturn \"Male\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a7e95-313b-4374-acfa-eeb617a403f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and tag distribution function\n",
    "def tokenize_and_distribute_tags(examples):\n",
    "\ttokenized_inputs = tokenizer(\n",
    "\t\texamples[\"tokens\"],\n",
    "\t\ttruncation=True,\n",
    "\t\tis_split_into_words=True,\n",
    "\t\tpadding='max_length',\n",
    "\t\tmax_length=128\n",
    "\t)\n",
    "\n",
    "\tlabels = []\n",
    "\tfor i, label in enumerate(examples[\"ner_tags\"]):\n",
    "\t\tword_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "\n",
    "\t\t# For loop written by Claude 3.5 Sonnet\n",
    "\t\t# It iterates through all the example tokens and classifies it as female or male\n",
    "\t\tmodified_labels = []\n",
    "\t\tfor j, tag in enumerate(label):\n",
    "\t\t\tif (tag == 1 or tag == 2) and isShortNonsense(examples[\"tokens\"][i][j]):\t# Implemented by myself, Drew Lickman\n",
    "\t\t\t\tmodified_labels.append(tag)\n",
    "\t\t\telif tag == 1:\t# If it's a B-PERSON tag\n",
    "\t\t\t\t# Check the actual token using examples[\"tokens\"][i][j]\n",
    "\t\t\t\tif is_female_name(examples[\"tokens\"][i][j]):\t# Implemented by myself, Drew Lickman\n",
    "\t\t\t\t\tmodified_labels.append(9)\t# Convert B-PERSON to B-FPER index\n",
    "\t\t\t\telif is_male_name(examples[\"tokens\"][i][j]):\t# Implemented by myself, Drew Lickman\n",
    "\t\t\t\t\tmodified_labels.append(1)\t# Convert B-PERSON to B-MPER index\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(examples[\"tokens\"][i][j]) # Print person tags that aren't classified male/female\n",
    "\t\t\t\t\tmodified_labels.append(tag)\n",
    "\t\t\telif tag == 2:\t# If it's an I-PERSON tag\t# Note: this might miss names split into more than 2 tokens\n",
    "\t\t\t\t# Keep the same type (MPER or FPER) as the previous B- tag\n",
    "\t\t\t\tif modified_labels[-1] == 9:\t# If previous was B-FPER\n",
    "\t\t\t\t\tmodified_labels.append(10)\t# I-FPER index\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tmodified_labels.append(2)\t# I-MPER index\n",
    "\t\t\telse:\t# Not a person tag\n",
    "\t\t\t\tmodified_labels.append(tag)\n",
    "\n",
    "\t\tlabel_ids = [-100 if word_id is None else modified_labels[word_id] for word_id in word_ids]\n",
    "\t\t#label_ids = [-100 if word_id is None else label[word_id] for word_id in word_ids]\n",
    "\t\t#print(f\"Tag List: {label_list}\\n\\nTokens: {examples['tokens'][0]}\\n\\nTokenized: {tokenized_inputs.tokens(batch_index=i)} \\\n",
    "\t\t#\\n\\nTags: {label}\\n\\nTokenized word ids: {word_ids}\\n\\nDistributed tags: {label_ids}\")\n",
    "\t\t#input()\n",
    "\t\tlabels.append(label_ids)\n",
    "\n",
    "\ttokenized_inputs[\"labels\"] = labels\n",
    "\treturn tokenized_inputs\n",
    "\n",
    "# Apply the tokenization function to the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_and_distribute_tags, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aa3111c-00ed-4f91-a0dd-87859c4fe4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric fucntion\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = \\\n",
    "        [ [label_list[label] for label in label_seq if label != -100] for label_seq in labels ]\n",
    "    model_predictions = \\\n",
    "        [ [label_list[pred] for (pred, label) in zip(pred_seq, label_seq) if label != -100] for pred_seq, label_seq in zip(predictions, labels) ]\n",
    "\n",
    "    results = metric.compute(predictions=model_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62951229-e1b6-4094-8c5d-b60e0f4620c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training arguments\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Instantiate trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9373f6-87c5-4c94-b2c1-a37e0a604a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97522582-7de3-4fd4-adbc-8084d21595c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "pred_labels = np.argmax(predictions.predictions, axis=2)\n",
    "true_labels = predictions.label_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
